{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xfFt0u5OQXrs","executionInfo":{"status":"ok","timestamp":1651333723506,"user_tz":240,"elapsed":9115,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"outputs":[],"source":["import os\n","import csv\n","import json\n","import logging\n","import math\n","from typing import List, Dict, Tuple, Callable, Iterable, Optional, Any\n","\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import pickle\n","import numpy as np\n","from keras.utils import np_utils\n","from sklearn.preprocessing import LabelEncoder\n","from numpy import save\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.metrics import classification_report\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1035,"status":"ok","timestamp":1651333724536,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"},"user_tz":240},"id":"qF3gDP8cRzCI","outputId":"1c611926-b1ab-4609-f9a4-ffcf633bc13d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","folder_ = 'drive/MyDrive/Masters/Year_1/Semester_2/CS_505/Project/'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8119,"status":"ok","timestamp":1651333732653,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"},"user_tz":240},"id":"jYn8iNg-Q9f4","outputId":"2afbbb97-3a9f-4cad-db77-a035afce58e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.18.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.12.0+cu113)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.96)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.5.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.11.0+cu113)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (4.2.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.49)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.8.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"]}],"source":["!pip install transformers\n","!pip install sentence_transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zLo6wg4XRBPV","executionInfo":{"status":"ok","timestamp":1651333734447,"user_tz":240,"elapsed":1797,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"outputs":[],"source":["from sentence_transformers import SentenceTransformer, models, InputExample, losses\n","from sentence_transformers.evaluation import LabelAccuracyEvaluator, SentenceEvaluator\n","from sentence_transformers.util import batch_to_device\n","from torch import Tensor\n","from torch.utils.data import DataLoader\n","from transformers import MT5EncoderModel, AutoConfig,T5Tokenizer\n","from transformers import pipeline, AutoTokenizer"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ymk91t-DWStx","executionInfo":{"status":"ok","timestamp":1651333734447,"user_tz":240,"elapsed":4,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"outputs":[],"source":["train_df=pd.read_csv(folder_ + 'Data/Train.csv')\n","train_df_english=pd.read_csv(folder_ + 'Data/train_google_translated.csv')\n","\n","#test_df=pd.read_csv('C:/Users/leose/second_semester/NLP/malawi_news_classification/data/test.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"a3w1gF-dWc_4","executionInfo":{"status":"ok","timestamp":1651333734447,"user_tz":240,"elapsed":4,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"outputs":[],"source":["train_df['Text']=train_df['Text'].tolist()\n","train_df_english['Text']=train_df_english['Text'].tolist()\n","#test_df['Text']=test_df['Text'].tolist()\n","#test_batch_sentences=[]\n","\n","#for frame in train_df['Text']:\n","#    train_batch_sentences.append(frame)\n","#for sentence in test_df['Text']:\n","#    test_batch_sentences.append(frame)"]},{"cell_type":"code","source":["print(len(train_df))\n","print(len(train_df_english))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2ka1QlWfkgH","executionInfo":{"status":"ok","timestamp":1651332172591,"user_tz":240,"elapsed":278,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"ab549342-d590-44f2-d69b-2702064b2816"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["1436\n","1436\n"]}]},{"cell_type":"code","source":["model = MT5EncoderModel.from_pretrained(\"google/mt5-small\")\n","tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n","#article = \"UN Offizier sagt, dass weiter verhandelt werden muss in Syrien.\"\n","#for sentence\n","#input_ids = tokenizer(train_batch_sentences[0], return_tensors=\"pt\",truncation=True,max_length=512).input_ids\n","#outputs = model(input_ids)\n","#hidden_state = outputs.last_hidden_state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAc27pTVgsMm","executionInfo":{"status":"ok","timestamp":1651333062073,"user_tz":240,"elapsed":5436,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"9a0de4b7-3455-487e-dac9-ad74ae099588"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/mt5-small were not used when initializing MT5EncoderModel: ['decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.final_layer_norm.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.embed_tokens.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'lm_head.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight']\n","- This IS expected if you are initializing MT5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing MT5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["'''\n","input_ids = []\n","#for frame in train_df['Text'][:400]:\n","lower = 1200\n","#upper = lower+400\n","upper = len(train_df)\n","for frame in train_df['Text'][lower:upper]:\n","    input_ids.append(tokenizer(frame, return_tensors=\"pt\",truncation=True,max_length=64).input_ids)\n","\n","outputs = []\n","for input_ in input_ids:\n","  outputs.append(model(input_))\n","\n","hidden_state = []\n","for output_ in outputs:\n","  hidden_state.append(output_.last_hidden_state)\n","\n","values = torch.zeros((400,512))\n","for i in range(len(hidden_state)):\n","  values[i] = (torch.mean(hidden_state[i][0],axis=0))\n","\n","#save(folder_ + 'Data/' + 'data_400_800.npy', values.detach().numpy())\n","\n","save(folder_ + 'Data/' + 'data_' + str(lower) + '_' + str(upper) + '.npy', values.detach().numpy())\n","'''"],"metadata":{"id":"9iT6nee9lWf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","input_ids = []\n","#for frame in train_df['Text'][:400]:\n","lower = 1200\n","#upper = lower+300\n","upper = len(train_df)\n","for frame in train_df_english['Text'][lower:upper]:\n","    input_ids.append(tokenizer(frame, return_tensors=\"pt\",truncation=True,max_length=64).input_ids)\n","\n","outputs = []\n","for input_ in input_ids:\n","  outputs.append(model(input_))\n","\n","hidden_state = []\n","for output_ in outputs:\n","  hidden_state.append(output_.last_hidden_state)\n","\n","values = torch.zeros((300,512))\n","for i in range(len(hidden_state)):\n","  values[i] = (torch.mean(hidden_state[i][0],axis=0))\n","\n","#save(folder_ + 'Data/' + 'data_400_800.npy', values.detach().numpy())\n","\n","save(folder_ + 'Data/' + 'data_' + str(lower) + '_' + str(upper) + '_english.npy', values.detach().numpy())\n","'''"],"metadata":{"id":"E5NQCDsAEYk4","executionInfo":{"status":"ok","timestamp":1651333136936,"user_tz":240,"elapsed":34461,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["li[3][236]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rV4qTBluiNpC","executionInfo":{"status":"ok","timestamp":1651306511066,"user_tz":240,"elapsed":176,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"bbc4d86f-1457-47a9-db32-b61b836e60d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0.], dtype=float32)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["lower = 0\n","upper = lower+400\n","li = []\n","for i in range(4):\n","  arr = np.load(folder_ + 'Data/' + 'data_' + str(lower) + '_' + str(upper) + '.npy')\n","  li.append(arr)\n","  lower+=400\n","  upper+=400\n","  if(lower == 1200):\n","    upper = 1436\n","  #break"],"metadata":{"id":"iqJWgCLOgT6n","executionInfo":{"status":"ok","timestamp":1651333735055,"user_tz":240,"elapsed":1,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["final_arr = np.vstack((li[0],li[1],li[2],li[3]))\n","final_arr = final_arr[:1436]"],"metadata":{"id":"wwHmDXLuh1Zl","executionInfo":{"status":"ok","timestamp":1651333736757,"user_tz":240,"elapsed":2,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["final_arr.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oL3annwaiB0q","executionInfo":{"status":"ok","timestamp":1651333739257,"user_tz":240,"elapsed":313,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"b78e9028-bb41-4fc2-de23-07e8d5910722"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1436, 512)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["final_arr[1435]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fE9lGXdeijgp","executionInfo":{"status":"ok","timestamp":1651333741305,"user_tz":240,"elapsed":271,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"2552e913-b815-4756-da7b-d0d78921af36"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-5.26638143e-02, -1.54549867e-01,  1.86291840e-02, -1.83572739e-01,\n","       -7.87804574e-02,  5.09037301e-02,  2.03488126e-01,  3.10577769e-02,\n","       -2.82362122e-02, -4.99501117e-02,  2.41595507e-01, -1.40947133e-01,\n","        3.49488258e-02, -1.30859837e-01,  6.62851632e-02, -8.03611204e-02,\n","       -1.00439146e-01, -3.87492739e-02, -8.31745118e-02,  6.70289844e-02,\n","        2.66414620e-02,  1.25922114e-01, -8.44994038e-02,  5.71737066e-02,\n","       -3.76449794e-01,  2.24952493e-02, -8.02223682e-01,  2.64139920e-02,\n","        9.43697542e-02,  1.39501467e-01,  6.02034554e-02,  9.61242914e-02,\n","       -1.40072122e-01, -8.43710750e-02,  2.26025637e-02,  8.08138996e-02,\n","       -6.60696030e-02,  1.28506556e-01,  3.32188196e-02, -2.54327714e-01,\n","        1.76303789e-01, -9.96564031e-02, -1.18747167e-01,  9.18802321e-02,\n","        9.74093527e-02, -1.41530484e-01,  8.24178755e-02, -1.24160178e-01,\n","        5.84548041e-02, -2.65140980e-02, -1.03624135e-01, -2.03897849e-01,\n","       -2.53316015e-02,  3.19525480e-01,  8.95995796e-02,  3.45133618e-02,\n","       -1.37856722e-01,  9.99978706e-02,  5.43730818e-02,  1.15518764e-01,\n","        5.23590483e-02, -5.62424026e-02,  1.46161437e-01,  2.01299518e-01,\n","       -7.15736579e-03, -8.16713572e-02, -1.32829517e-01,  6.61594942e-02,\n","        2.15490498e-02,  1.00259408e-01,  5.52325025e-02,  5.44385836e-02,\n","       -1.95129633e-01, -3.28413695e-02,  3.12885195e-01,  6.94027692e-02,\n","        2.03671426e-01,  1.92085534e-01,  1.26195308e-02, -4.64701131e-02,\n","       -7.73701146e-02,  5.27003556e-02, -1.45031184e-01,  1.51025683e-01,\n","        1.64008886e-03,  1.72960922e-01, -2.12891996e-01, -9.85172242e-02,\n","       -1.20727442e-01, -1.14161044e-01,  2.65220046e-01,  1.65285245e-01,\n","        4.34007309e-03,  5.66615164e-02,  1.51842207e-01, -4.16501015e-02,\n","       -7.58082978e-03, -6.46937732e-03,  2.07331423e-02, -7.26304278e-02,\n","        1.23031372e-02,  9.20572728e-02,  7.35855252e-02, -4.40784395e-02,\n","       -6.03277236e-03,  1.52477100e-01, -2.13034958e-01, -1.66834183e-02,\n","        6.35157228e-02, -3.59152444e-03,  1.84002630e-02, -7.40803964e-03,\n","        1.21420987e-01, -6.83190078e-02,  3.66696157e-02, -3.51688676e-02,\n","       -5.85225262e-02, -1.37004312e-02, -1.14075996e-01, -1.82566762e-01,\n","        1.36644945e-01,  1.30314931e-01, -9.69058573e-02, -1.07021788e-02,\n","        9.94865522e-02, -5.63222617e-02, -1.31119132e-01,  3.76661792e-02,\n","        8.12636390e-02, -3.05430554e-02,  8.36031511e-02, -9.83496010e-03,\n","        1.30291674e-02,  2.65807152e-01, -2.00400233e-01, -1.53203644e-02,\n","        5.37604466e-02,  4.66570184e-02, -1.65600583e-01, -5.75195998e-02,\n","        7.67391026e-02,  4.28453535e-02,  2.07444131e-01,  3.70600335e-02,\n","        4.19520810e-02, -7.84106851e-02,  1.78685989e-02,  4.97287437e-02,\n","       -1.70424543e-02, -4.85331006e-02,  1.27713839e-02,  1.60920009e-01,\n","        6.67521134e-02, -7.45074078e-02,  1.89169675e-01,  1.99192479e-01,\n","        2.28387490e-02,  4.15583923e-02, -2.34091133e-02,  1.07122943e-01,\n","       -1.02412179e-01,  2.28151716e-02,  4.73674685e-02,  1.90203637e-03,\n","       -8.77431184e-02, -7.28843659e-02, -6.36630207e-02, -1.08255912e-02,\n","       -1.59330815e-01,  6.12560175e-02,  4.34848666e-01, -1.06545016e-01,\n","       -1.66681617e-01,  1.51762575e-01, -5.64533994e-02,  1.93678252e-02,\n","        5.98113611e-02,  6.07514009e-03,  6.87266588e-02,  2.84647495e-02,\n","       -1.22467391e-02, -1.25998631e-01, -2.20204070e-01, -8.81007984e-02,\n","       -9.03305560e-02,  2.94103742e-01,  1.01368539e-01, -1.86778046e-03,\n","        3.37035693e-02,  2.02132255e-01, -8.07272643e-02,  1.48600519e-01,\n","        1.08908474e-01, -3.59218102e-03,  4.38558422e-02, -8.02270398e-02,\n","        1.63984746e-02,  4.64711748e-02, -1.52805135e-01,  9.86678302e-02,\n","       -9.24151614e-02,  1.03457533e-01, -4.88512181e-02,  1.03919640e-01,\n","        1.00135893e-01, -4.04176749e-02,  1.32232890e-01,  3.06031585e-01,\n","       -2.97685236e-01, -2.87916735e-02,  1.16827473e-01,  6.02365434e-02,\n","        1.25803038e-01,  4.68919352e-02, -2.27374583e-01, -1.34950895e-02,\n","       -2.30651319e-01,  3.47336419e-02,  1.56002924e-01, -1.81914613e-01,\n","       -1.43585624e-02, -2.75655501e-02,  1.16235159e-01, -1.60535723e-01,\n","        2.84683853e-02,  6.01115115e-02, -1.68739166e-03, -5.14156669e-02,\n","        1.59820560e-02, -8.68215561e-02, -7.73929805e-02,  6.84751496e-02,\n","       -6.19345009e-02, -2.93068141e-01,  1.83482066e-01, -2.52257109e-01,\n","       -1.83050185e-02, -1.53688312e-01, -9.98862311e-02,  2.61963531e-02,\n","       -6.82485104e-02,  1.45700285e-02,  3.63601670e-02,  1.29102349e-01,\n","       -8.45860243e-02,  4.09019366e-02,  9.14121643e-02,  8.89118947e-03,\n","        7.64350593e-02,  3.96740511e-02,  5.80817126e-02,  2.19590038e-01,\n","       -2.43964270e-01, -1.23355463e-01, -1.49499893e-01,  1.05336169e-02,\n","       -2.54373066e-03, -1.23659506e-01, -1.53258219e-01,  1.39171094e-01,\n","        2.39410978e-02, -1.59908965e-01,  1.36237696e-01,  2.66771559e-02,\n","        5.70354685e-02, -1.16055697e-01,  1.10642374e-01,  1.63493365e-01,\n","        9.12906602e-02,  2.01230645e-01,  6.11539446e-02,  6.15969673e-02,\n","       -1.04372859e-01,  1.31315917e-01, -1.91992998e-01, -8.64006877e-02,\n","       -1.92857385e-01, -2.56903712e-02,  4.95558605e-02,  5.12255095e-02,\n","        7.83499777e-02,  9.77366269e-02, -1.00987814e-02,  7.61512816e-02,\n","       -4.84074503e-02, -1.15997344e-01,  7.08467811e-02, -9.45090204e-02,\n","       -1.16377428e-01, -1.14510864e-01,  9.95045155e-02, -1.56261802e-01,\n","        1.40327007e-01,  1.25478934e-02, -4.12145965e-02,  6.60455525e-02,\n","       -2.35514268e-01,  2.03866243e-01, -1.29009470e-01, -8.80269855e-02,\n","        2.72480100e-02,  1.60330296e-01, -1.00368291e-01,  2.52620071e-01,\n","        5.35425656e-02, -1.31280348e-03,  3.82950157e-02,  9.25519466e-02,\n","       -1.31841674e-02,  7.01957345e-02, -9.06717852e-02, -6.84394389e-02,\n","        8.25576112e-02,  1.17681101e-01, -1.03465356e-01, -2.04246610e-01,\n","       -1.39979869e-01,  1.03539132e-01,  2.58387148e-01,  2.60101289e-01,\n","       -3.85038666e-02,  1.17744684e-01,  1.56042695e-01,  6.72942325e-02,\n","        1.47902772e-01, -1.85423158e-02,  1.11114793e-01, -2.01154470e-01,\n","        1.81593984e-01, -2.14856155e-02,  1.75494567e-01,  4.51606996e-02,\n","        1.62038490e-01,  2.18230695e-01, -9.11282718e-01,  6.09733909e-02,\n","        2.58296102e-01,  1.04662806e-01,  1.78261131e-01, -8.99904501e-03,\n","        5.75225055e-03, -2.64490426e-01, -4.83387057e-03, -1.38247889e-02,\n","        3.31332907e-03,  1.04151890e-01,  3.86089757e-02, -1.00115083e-01,\n","        1.32713541e-01, -8.00608322e-02, -9.05360058e-02,  1.52382940e-01,\n","        4.24793288e-02,  1.16402462e-01, -6.76897615e-02, -2.03461736e-01,\n","       -1.25644267e-01, -7.70081878e-02, -8.02530125e-02, -5.21805063e-02,\n","       -1.66667461e-01, -1.96932349e-02,  3.61401401e-02, -4.33397852e-02,\n","        5.34897633e-02,  7.03781173e-02, -8.45212787e-02, -1.36547163e-02,\n","       -4.32205275e-02,  1.50603354e-01,  8.33128393e-02, -4.43487689e-02,\n","       -2.11007595e-01,  1.18032731e-02,  6.38430864e-02,  1.02490187e-01,\n","        2.39510000e-01,  2.81302370e-02, -1.34560719e-01, -5.83842099e-02,\n","        1.92560226e-01,  1.25440568e-01,  2.11941469e-02, -1.32612493e-02,\n","        1.47220075e-01, -2.31947042e-02,  1.46421399e-02, -2.49647066e-01,\n","       -1.54333144e-01,  1.49464041e-01, -5.03290966e-02,  1.10406011e-01,\n","       -1.32251889e-01,  1.13028467e-01,  2.24649087e-02, -3.72478627e-02,\n","        1.79788977e-01, -2.99319867e-02,  3.63363698e-02, -9.70552266e-02,\n","       -3.80267292e-01,  1.75725758e-01, -7.84628093e-04, -6.43532872e-02,\n","       -1.10025331e-03, -4.60098758e-02, -5.97702041e-02,  2.74307281e-01,\n","        9.14940238e-02,  1.98515058e-01,  1.10981666e-01,  2.66756788e-02,\n","        9.95992571e-02,  2.65155584e-01, -1.88547015e-01,  5.70510477e-02,\n","        6.80383295e-02, -9.27495677e-03, -6.88922033e-03, -2.84931622e-03,\n","        1.26089573e-01, -2.85950541e-01, -7.02556968e-02, -6.54159114e-02,\n","        1.93061128e-01, -1.14788674e-03, -2.33587861e-01, -2.57853061e-01,\n","        3.30265760e-02, -1.29136115e-01,  9.29212198e-02,  5.95380217e-02,\n","       -3.41211110e-02, -4.38082181e-02, -1.10919841e-01,  2.27427222e-02,\n","        8.65283012e-02,  2.88263828e-01, -9.83277149e-03, -1.58650801e-02,\n","       -2.82354858e-02, -8.66629630e-02, -4.69342954e-02,  9.25438106e-02,\n","       -7.49834068e-03,  3.00962292e-02,  7.72748441e-02, -1.08783871e-01,\n","       -1.15425050e+00,  6.89635798e-03,  2.16822222e-01,  4.65432927e-02,\n","        1.33184835e-01, -1.54873401e-01, -1.59638852e-01,  1.17132723e-01,\n","       -1.62228733e-01, -6.45145327e-02,  1.95824429e-02, -5.81652038e-02,\n","       -8.59958977e-02,  1.37422249e-01, -9.56564397e-02,  6.11605160e-02,\n","       -2.84923941e-01, -9.92775336e-02,  5.50487600e-02, -1.49312973e-01,\n","       -1.21408641e-01, -2.81025469e-03,  5.60866296e-03, -1.35805696e-01,\n","        1.44643247e-01, -7.28355423e-02, -1.95351243e-01,  7.34647550e-03,\n","        1.15119711e-01, -3.65398318e-01,  1.15840919e-02,  9.65188891e-02,\n","       -8.28015655e-02, -1.09136909e-01, -5.30389994e-02, -8.45767260e-02,\n","        4.41003777e-02,  1.09006256e-01, -7.37665892e-02,  3.83598357e-02,\n","        1.42098874e-01,  9.62611958e-02,  1.54669389e-01,  2.07591131e-02,\n","        4.86616045e-04,  4.73585725e-01,  1.09629884e-01, -5.68518676e-02,\n","       -1.12470478e-01,  9.79526192e-02, -1.45631433e-01, -3.64814065e-02,\n","       -5.41577339e-02,  1.30781218e-01,  1.01605915e-02,  4.57620472e-01,\n","       -1.81682751e-01, -7.14427680e-02,  2.77616009e-02, -8.93072337e-02,\n","       -4.32648398e-02, -8.62880237e-03, -2.13946737e-02,  5.90836257e-02],\n","      dtype=float32)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["lower = 0\n","upper = lower+300\n","li = []\n","for i in range(5):\n","  arr_english = np.load(folder_ + 'Data/' + 'data_' + str(lower) + '_' + str(upper) + '_english.npy')\n","  li.append(arr_english)\n","  lower+=300\n","  upper+=300\n","  if(lower == 1200):\n","    upper = 1436\n","  #break"],"metadata":{"id":"BGu-XATaIJL6","executionInfo":{"status":"ok","timestamp":1651333744678,"user_tz":240,"elapsed":292,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["len(li)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8DoqlANIbpc","executionInfo":{"status":"ok","timestamp":1651333746625,"user_tz":240,"elapsed":212,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"5c72ffa5-ec64-4c6f-d0c9-46402eaed055"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["final_arr_english = np.vstack((li[0],li[1],li[2],li[3],li[4]))\n","final_arr_english = final_arr_english[:1436]"],"metadata":{"id":"os0Cc4n0ILLa","executionInfo":{"status":"ok","timestamp":1651333748070,"user_tz":240,"elapsed":8,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["final_arr_english.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xh08zp4FIjAT","executionInfo":{"status":"ok","timestamp":1651333750582,"user_tz":240,"elapsed":220,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"fa5b46d0-d091-45ef-956a-38a039e04627"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1436, 512)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["final_arr_english[1435]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6czTR1z6Id6U","executionInfo":{"status":"ok","timestamp":1651333752562,"user_tz":240,"elapsed":306,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"bf5dac7e-c0ea-4f8b-cacd-a06647f690bb"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-6.14335388e-03, -1.90163970e-01, -7.79935271e-02, -5.37078232e-02,\n","       -1.34949416e-01,  8.67662057e-02,  1.90029353e-01,  9.86115262e-03,\n","       -9.85435396e-02, -2.05613688e-01,  2.08218664e-01, -2.84024663e-02,\n","       -2.41926871e-03, -7.43922740e-02,  1.97681084e-01, -2.58285757e-02,\n","        2.02874959e-01, -5.60942814e-02, -5.10451198e-02,  1.78223088e-01,\n","        1.00612864e-01,  1.66835755e-01, -8.99607316e-03,  5.08847833e-02,\n","       -2.06167102e-02,  1.11117968e-02, -7.96199322e-01, -1.24473333e-01,\n","       -2.43776798e-01,  2.05756411e-01,  2.60200873e-02,  3.94259430e-02,\n","       -1.42344171e-02, -1.51687041e-02, -6.54334947e-02, -1.68005362e-01,\n","       -8.85375738e-02,  2.33345315e-01,  2.74571210e-01, -1.83020294e-01,\n","        1.27800360e-01, -4.90180254e-02,  1.82920266e-02,  2.11384982e-01,\n","        6.73183203e-02,  1.56480849e-01,  4.25525159e-02, -7.31685311e-02,\n","       -2.55722702e-02,  1.26586221e-02, -1.39706284e-01, -2.57001668e-01,\n","       -2.41024438e-02,  3.43045294e-01, -3.32647003e-02, -3.59819387e-03,\n","       -5.93516938e-02,  8.07708129e-03,  1.50735304e-02,  1.94971442e-01,\n","        1.57797664e-01, -2.55117510e-02,  1.67719856e-01,  2.08010048e-01,\n","       -8.48627687e-02,  2.26649456e-02, -5.75711913e-02, -2.76044682e-02,\n","       -3.53539661e-02,  3.48392911e-02, -3.51174660e-02, -1.03397090e-02,\n","       -6.44277483e-02, -3.34711730e-01,  2.27825522e-01,  1.52976178e-02,\n","        9.44777504e-02,  7.98047185e-02,  7.17715099e-02,  5.25651276e-02,\n","       -1.42695010e-02,  2.53665328e-01, -6.15133345e-03, -2.12625623e-01,\n","        5.76381832e-02,  2.15438724e-01, -2.62080938e-01, -1.24714687e-01,\n","       -7.53860027e-02,  7.99836218e-02,  8.72362405e-02,  2.02662796e-01,\n","       -8.89849886e-02,  2.27370253e-03,  1.80146098e-02, -1.06229343e-01,\n","       -7.90759400e-02,  2.18181908e-01,  4.96762246e-02, -9.11920145e-02,\n","        2.41307057e-02,  6.41869009e-02,  3.05066369e-02, -8.66144430e-03,\n","        1.46880716e-01,  1.22551627e-01, -3.14931870e-01,  5.67638762e-02,\n","        5.58132865e-02,  1.63263418e-02,  2.19415948e-02, -3.47694382e-02,\n","        1.48929015e-01,  1.10227309e-01, -3.15802335e-03, -5.12147695e-02,\n","       -6.75746575e-02,  7.99598247e-02,  4.30253446e-02, -1.19541064e-01,\n","        4.48050909e-02,  1.58367023e-01, -8.38665813e-02,  2.16908991e-01,\n","        5.49446791e-02,  2.17111260e-02,  1.79198384e-01,  1.12554796e-01,\n","       -2.09857114e-02, -4.62449566e-02, -6.77755624e-02, -3.73612233e-02,\n","        3.91323380e-02, -3.42745781e-02,  1.49115801e-01, -3.60295512e-02,\n","       -8.34148843e-03,  5.69553897e-02,  4.12130989e-02, -3.54483947e-02,\n","        1.55724972e-01,  6.23203116e-03,  1.33496255e-01,  9.83284414e-03,\n","       -1.06822416e-01,  5.73600158e-02,  2.08241921e-02, -6.40102625e-02,\n","        2.62823720e-02, -9.08786282e-02, -4.60515246e-02,  6.89474121e-03,\n","        2.75719166e-02,  2.54614174e-01,  5.93150184e-02,  3.84230688e-02,\n","       -1.80820152e-01, -7.00572357e-02,  1.16464429e-01, -6.21979311e-03,\n","        1.08249351e-01, -7.88232833e-02,  2.04916503e-02, -4.64371219e-02,\n","       -1.22400045e-01, -2.08116136e-02, -7.40208030e-02, -8.96043554e-02,\n","       -1.96003541e-01,  1.25568956e-01,  5.49039066e-01, -4.14721780e-02,\n","       -6.78155273e-02,  3.83606791e-01,  2.41811760e-02,  4.88199145e-02,\n","       -5.60421795e-02, -1.46638095e-01, -8.09338242e-02,  6.04037195e-02,\n","       -5.47746271e-02, -3.20459269e-02, -1.60433859e-01,  1.23884365e-01,\n","        1.35759600e-02,  1.92535162e-01,  1.82428047e-01,  2.64345333e-02,\n","        2.98591312e-02, -6.39765896e-03,  1.34116486e-01, -3.09701189e-02,\n","       -1.38677284e-02,  4.87182289e-04,  7.81509280e-03, -7.29201511e-02,\n","       -2.02229992e-01,  2.14116499e-02, -8.40456188e-02,  1.35506034e-01,\n","        1.26211261e-02,  9.20982137e-02, -1.27715439e-01,  2.78621987e-02,\n","        3.00317947e-02, -3.01250853e-02,  6.72312304e-02,  2.58125275e-01,\n","       -7.78402612e-02, -9.70353484e-02, -3.83145623e-02, -3.91295776e-02,\n","       -3.75410914e-03,  3.41608785e-02, -1.54026508e-01, -6.16825074e-02,\n","       -1.42229721e-01, -9.04811323e-02,  2.07381040e-01, -1.26619115e-01,\n","        1.14679828e-01, -3.43126953e-02,  7.03274161e-02,  8.07513893e-02,\n","        3.97040769e-02, -1.13730863e-01, -1.48131013e-01,  2.76054889e-02,\n","       -3.22320648e-02, -4.41539735e-02, -1.09170467e-01,  2.43849922e-02,\n","       -4.33001548e-01,  1.19480744e-01,  8.00964683e-02,  5.88245504e-02,\n","        3.26044261e-02,  9.51447040e-02,  1.93916887e-01,  1.05109505e-01,\n","       -5.84018417e-02, -1.56675488e-01,  7.68381506e-02,  1.90620214e-01,\n","       -2.97970809e-02,  1.31357253e-01,  2.18546912e-02, -1.47292137e-01,\n","        6.56141788e-02, -1.62764564e-01,  2.30389219e-02,  2.67115742e-01,\n","       -1.56314582e-01,  9.63805169e-02,  2.63539478e-02,  5.61207905e-03,\n","       -1.65112019e-01, -3.23868208e-02,  5.96262421e-03,  7.57082477e-02,\n","       -1.62839778e-02,  2.86477692e-02, -1.32148825e-02,  9.46322531e-02,\n","        1.51296392e-01, -1.07705086e-01,  1.03131279e-01,  1.17787652e-01,\n","        7.40047544e-05,  1.47805825e-01,  7.20097274e-02, -6.11488335e-03,\n","       -1.43656641e-01, -3.70052643e-03, -8.96467119e-02,  1.69031784e-01,\n","       -9.55121871e-03, -1.39615566e-01,  1.16515964e-01,  9.66761410e-02,\n","        1.00670680e-01,  3.07700504e-03, -4.00481895e-02,  2.54642479e-02,\n","       -1.21278360e-01, -9.77035239e-02,  1.89250074e-02,  6.89554587e-02,\n","       -7.37355649e-02,  1.98624339e-02,  1.88472793e-02, -1.31078079e-01,\n","        1.76653434e-02, -3.63987312e-03, -3.18886600e-02,  3.74377035e-02,\n","       -3.05179525e-02, -5.13795391e-02,  5.61037585e-02, -2.31814474e-01,\n","        9.03347582e-02,  3.71196456e-02,  8.00014809e-02,  2.75821090e-01,\n","        3.08165289e-02,  1.00976966e-01,  4.61320952e-02, -1.06182098e-01,\n","       -4.49611768e-02,  6.03720844e-02,  6.26830086e-02, -1.51984513e-01,\n","       -1.05616778e-01,  8.80058929e-02, -5.22049069e-02, -1.49674401e-01,\n","       -3.94489132e-02,  8.90429616e-02,  1.09838516e-01,  1.07362784e-01,\n","       -6.90475851e-02, -3.40753868e-02, -1.96016673e-02,  7.58275390e-02,\n","       -9.70885158e-04, -8.80279243e-02,  1.42517593e-03,  3.88910547e-02,\n","        2.13411391e-01, -1.28984749e-01,  1.79822624e-01,  8.01952928e-02,\n","        1.47554711e-01,  1.07467152e-01, -9.03240919e-01,  5.03942743e-02,\n","        1.63058892e-01,  1.27956495e-01,  9.80803370e-02,  6.49754778e-02,\n","        1.04276203e-02, -2.47966886e-01, -1.47769690e-01,  2.25997865e-02,\n","       -4.83138002e-02,  2.97067054e-02,  5.13937101e-02, -1.54366791e-01,\n","        8.43273550e-02,  4.98360116e-03, -1.26508266e-01,  3.22375037e-02,\n","        1.65421758e-02,  7.64122382e-02, -7.50380829e-02, -3.22205067e-01,\n","        1.30163319e-03, -1.04422636e-01,  2.10329369e-02, -6.06828555e-02,\n","        4.26962972e-02,  1.35720462e-01,  1.60255536e-01, -1.18707791e-01,\n","       -6.27145451e-03,  3.90409753e-02, -1.36520922e-01, -2.21992042e-02,\n","       -1.01088345e-01, -2.37909332e-03,  1.14655405e-01,  1.87083744e-02,\n","       -1.11276843e-01, -6.36458993e-02,  4.17887531e-02,  1.43794969e-01,\n","        2.16261312e-01, -3.73263061e-02,  8.88592675e-02,  4.06996459e-02,\n","        1.14134707e-01, -1.04241475e-01, -5.94804659e-02,  2.30552303e-03,\n","        1.64702222e-01,  3.00600263e-03, -9.81625263e-03, -9.75643694e-02,\n","       -1.80341348e-01, -4.54726443e-02,  3.96407917e-02, -6.58273622e-02,\n","        9.68037769e-02,  9.63008106e-02, -2.21379381e-03, -5.14180586e-02,\n","       -2.24601105e-01,  8.16716533e-03, -7.98905119e-02, -1.47360265e-01,\n","       -1.24791622e-01,  6.84631020e-02,  6.27126619e-02,  1.02880135e-01,\n","       -6.27286732e-02,  8.90959203e-02, -1.77658096e-01,  1.14282019e-01,\n","       -1.12911932e-01,  1.17728204e-01,  6.23617731e-02, -1.80503121e-03,\n","        8.84699300e-02,  1.42686069e-01, -1.76054373e-01,  3.15527618e-02,\n","        3.41219734e-03,  1.14054121e-01,  2.32568353e-01, -3.80592942e-02,\n","       -2.50382662e-01, -2.88746178e-01,  1.00936994e-01, -1.01802483e-01,\n","        6.93281814e-02, -2.24460363e-02,  9.15601999e-02,  3.06132808e-02,\n","       -5.99818639e-02, -4.44818623e-02,  3.12802084e-02,  3.18728626e-01,\n","       -8.27406123e-02,  2.63407789e-02,  5.39429560e-02,  6.78128004e-02,\n","       -1.07665122e-01,  1.10214025e-01,  3.73696893e-01, -1.02681890e-01,\n","       -7.59242550e-02,  7.65764490e-02,  3.82829867e-02, -1.90870091e-02,\n","       -2.01781243e-01,  9.70891267e-02,  2.72704452e-01, -1.24591678e-01,\n","       -1.37967861e+00,  2.03059465e-02,  1.12692356e-01,  1.49597377e-02,\n","        1.36236742e-01,  5.22973388e-02,  9.91930999e-03,  2.22964942e-01,\n","       -8.13601986e-02,  8.23386237e-02, -1.39101967e-01, -3.46237794e-02,\n","        3.44835594e-02,  4.38009836e-02,  4.67081219e-02,  1.70103729e-01,\n","       -8.42037797e-02, -6.34868145e-02,  3.05933375e-02, -2.98992824e-02,\n","       -6.09750785e-02,  1.72438890e-01, -6.33944646e-02,  5.41451424e-02,\n","        9.34077725e-02, -6.18527755e-02, -1.27436057e-01,  3.14205848e-02,\n","       -2.88406089e-02, -1.80735230e-01,  5.41676581e-02, -5.62813953e-02,\n","       -6.68026283e-02,  2.40971334e-02,  2.03502662e-02, -2.85365917e-02,\n","       -3.72843780e-02,  1.33951396e-01, -4.60534096e-02,  2.18212921e-02,\n","        1.11450762e-01,  5.84536418e-02,  2.56440341e-01, -1.92769900e-01,\n","        1.24673449e-01,  1.09217502e-01,  6.02594838e-02, -7.62318522e-02,\n","       -4.76883352e-02,  4.13608290e-02, -4.67879474e-02,  2.31003202e-02,\n","        5.24685495e-02, -6.27278239e-02,  1.24654271e-01, -9.96248797e-02,\n","       -1.73628196e-01, -1.58608273e-01,  1.11878969e-01, -7.19980150e-02,\n","       -3.65611799e-02,  1.87685773e-01, -4.76815701e-02, -1.57192692e-01],\n","      dtype=float32)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["final_comb_arr = np.hstack((final_arr,final_arr_english))"],"metadata":{"id":"f7vR0qPgJMlq","executionInfo":{"status":"ok","timestamp":1651333756252,"user_tz":240,"elapsed":207,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["final_comb_arr.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IvRsJtP9JgRY","executionInfo":{"status":"ok","timestamp":1651333758543,"user_tz":240,"elapsed":345,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"4e5f5b05-22e1-4ea6-831b-a4a1f5c5243e"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1436, 1024)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["np.unique(train_df['Label']).shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSeJZ_5pne4Y","executionInfo":{"status":"ok","timestamp":1651333760105,"user_tz":240,"elapsed":348,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"ed4b2f78-e67c-48dc-b56a-7b71bf35e001"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["le = LabelEncoder()\n","train_df.Label = le.fit_transform(train_df.Label)"],"metadata":{"id":"AghmKiVUoB7G","executionInfo":{"status":"ok","timestamp":1651333762911,"user_tz":240,"elapsed":2,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["Y_train = np_utils.to_categorical(train_df['Label'], np.unique(train_df['Label']).shape[0])"],"metadata":{"id":"zbxR9sxTnO8t","executionInfo":{"status":"ok","timestamp":1651333764900,"user_tz":240,"elapsed":354,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print(Y_train.shape)\n","print(Y_train[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YiNySUtzoH-O","executionInfo":{"status":"ok","timestamp":1651333767319,"user_tz":240,"elapsed":317,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"295fd433-c4ca-4bdb-e7c0-970a8115e4d8"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["(1436, 20)\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}]},{"cell_type":"code","source":["print('Building model...')\n","model = Sequential()\n","model.add(Dense(2048, input_shape=(1024,)))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(20))\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#make one, takes in, double that amount, english and chichewa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZhUUJbJoQ_x","executionInfo":{"status":"ok","timestamp":1651333769755,"user_tz":240,"elapsed":215,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"8a92789f-ab5b-4134-cbef-86563f23b536"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Building model...\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RlXfKNP2oyPU","executionInfo":{"status":"ok","timestamp":1651333773047,"user_tz":240,"elapsed":309,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"fcf45401-2aa0-452a-f419-0eb6f15b734f"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 2048)              2099200   \n","                                                                 \n"," activation (Activation)     (None, 2048)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 20)                40980     \n","                                                                 \n"," activation_1 (Activation)   (None, 20)                0         \n","                                                                 \n","=================================================================\n","Total params: 2,140,180\n","Trainable params: 2,140,180\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(\n","        final_comb_arr, Y_train, test_size=0.3, random_state=42, stratify=Y_train)"],"metadata":{"id":"NLzLqYgEjM0y","executionInfo":{"status":"ok","timestamp":1651333777964,"user_tz":240,"elapsed":243,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebg0U5ORjccQ","executionInfo":{"status":"ok","timestamp":1651333780834,"user_tz":240,"elapsed":271,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"08cf5dc2-57f7-4408-e388-95e510bad514"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1005, 1024)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["X_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sB8KC9CvKdpr","executionInfo":{"status":"ok","timestamp":1651333788156,"user_tz":240,"elapsed":264,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"4ac61ca9-3520-4990-9ffb-4aa03b9adb95"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.02751722, -0.00119188, -0.05982733, ...,  0.194644  ,\n","        0.17343605, -0.28630933], dtype=float32)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["y_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8zM6igJjeF2","executionInfo":{"status":"ok","timestamp":1651333793115,"user_tz":240,"elapsed":306,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"0e8573fe-186b-4b3d-aeec-71cc27b4494c"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n","       0., 0., 0.], dtype=float32)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["#train_dataset = tf.data.Dataset.from_tensor_slices((values.detach().numpy(), Y_train[:400]))\n","train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"],"metadata":{"id":"3y0MmA6cWxK2","executionInfo":{"status":"ok","timestamp":1651333798441,"user_tz":240,"elapsed":310,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"gdvG8KAVZNuP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 32\n","SHUFFLE_BUFFER_SIZE = 100\n","\n","train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","test_dataset = test_dataset.batch(BATCH_SIZE)"],"metadata":{"id":"0BFtZ67-XLN6","executionInfo":{"status":"ok","timestamp":1651333804586,"user_tz":240,"elapsed":311,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["result = model.fit(train_dataset,\n","                    epochs=100, batch_size=32,\n","                    verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJq_So_aW6X_","executionInfo":{"status":"ok","timestamp":1651333867729,"user_tz":240,"elapsed":59972,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"9bfa91c2-9cc9-40cc-c7cf-4b2df7aa78fa"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","32/32 [==============================] - 1s 12ms/step - loss: 2.3811 - accuracy: 0.2806\n","Epoch 2/100\n","32/32 [==============================] - 0s 11ms/step - loss: 1.8483 - accuracy: 0.4577\n","Epoch 3/100\n","32/32 [==============================] - 0s 12ms/step - loss: 1.6069 - accuracy: 0.5274\n","Epoch 4/100\n","32/32 [==============================] - 0s 13ms/step - loss: 1.4206 - accuracy: 0.5721\n","Epoch 5/100\n","32/32 [==============================] - 0s 12ms/step - loss: 1.2985 - accuracy: 0.6010\n","Epoch 6/100\n","32/32 [==============================] - 0s 12ms/step - loss: 1.1509 - accuracy: 0.6478\n","Epoch 7/100\n","32/32 [==============================] - 0s 12ms/step - loss: 1.0605 - accuracy: 0.6507\n","Epoch 8/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.9446 - accuracy: 0.7144\n","Epoch 9/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.8777 - accuracy: 0.7274\n","Epoch 10/100\n","32/32 [==============================] - 0s 14ms/step - loss: 0.8129 - accuracy: 0.7433\n","Epoch 11/100\n","32/32 [==============================] - 1s 17ms/step - loss: 0.7312 - accuracy: 0.7662\n","Epoch 12/100\n","32/32 [==============================] - 1s 16ms/step - loss: 0.6944 - accuracy: 0.7771\n","Epoch 13/100\n","32/32 [==============================] - 1s 24ms/step - loss: 0.6209 - accuracy: 0.8100\n","Epoch 14/100\n","32/32 [==============================] - 1s 21ms/step - loss: 0.5811 - accuracy: 0.8269\n","Epoch 15/100\n","32/32 [==============================] - 1s 20ms/step - loss: 0.5370 - accuracy: 0.8388\n","Epoch 16/100\n","32/32 [==============================] - 1s 21ms/step - loss: 0.4588 - accuracy: 0.8746\n","Epoch 17/100\n","32/32 [==============================] - 1s 17ms/step - loss: 0.4006 - accuracy: 0.9055\n","Epoch 18/100\n","32/32 [==============================] - 1s 16ms/step - loss: 0.4115 - accuracy: 0.8896\n","Epoch 19/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.3228 - accuracy: 0.9343\n","Epoch 20/100\n","32/32 [==============================] - 0s 15ms/step - loss: 0.2853 - accuracy: 0.9443\n","Epoch 21/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.2777 - accuracy: 0.9383\n","Epoch 22/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.2471 - accuracy: 0.9542\n","Epoch 23/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.2495 - accuracy: 0.9502\n","Epoch 24/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.2446 - accuracy: 0.9353\n","Epoch 25/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.2050 - accuracy: 0.9622\n","Epoch 26/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.1817 - accuracy: 0.9672\n","Epoch 27/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.1699 - accuracy: 0.9672\n","Epoch 28/100\n","32/32 [==============================] - 0s 11ms/step - loss: 0.1439 - accuracy: 0.9861\n","Epoch 29/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.1418 - accuracy: 0.9771\n","Epoch 30/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.1434 - accuracy: 0.9751\n","Epoch 31/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.1065 - accuracy: 0.9861\n","Epoch 32/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0911 - accuracy: 0.9970\n","Epoch 33/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0795 - accuracy: 0.9970\n","Epoch 34/100\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0736 - accuracy: 0.9980\n","Epoch 35/100\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0728 - accuracy: 0.9960\n","Epoch 36/100\n","32/32 [==============================] - 0s 16ms/step - loss: 0.0685 - accuracy: 0.9980\n","Epoch 37/100\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0585 - accuracy: 0.9980\n","Epoch 38/100\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0497 - accuracy: 1.0000\n","Epoch 39/100\n","32/32 [==============================] - 0s 15ms/step - loss: 0.0476 - accuracy: 0.9990\n","Epoch 40/100\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0431 - accuracy: 0.9990\n","Epoch 41/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0400 - accuracy: 1.0000\n","Epoch 42/100\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0370 - accuracy: 1.0000\n","Epoch 43/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0388 - accuracy: 1.0000\n","Epoch 44/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0376 - accuracy: 0.9990\n","Epoch 45/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0342 - accuracy: 0.9990\n","Epoch 46/100\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0341 - accuracy: 1.0000\n","Epoch 47/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0310 - accuracy: 1.0000\n","Epoch 48/100\n","32/32 [==============================] - 1s 18ms/step - loss: 0.0278 - accuracy: 1.0000\n","Epoch 49/100\n","32/32 [==============================] - 1s 16ms/step - loss: 0.0263 - accuracy: 1.0000\n","Epoch 50/100\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0243 - accuracy: 1.0000\n","Epoch 51/100\n","32/32 [==============================] - 1s 19ms/step - loss: 0.0256 - accuracy: 1.0000\n","Epoch 52/100\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0200 - accuracy: 1.0000\n","Epoch 53/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 1.0000\n","Epoch 54/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9990\n","Epoch 55/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9990\n","Epoch 56/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 1.0000\n","Epoch 57/100\n","32/32 [==============================] - 1s 17ms/step - loss: 0.0196 - accuracy: 1.0000\n","Epoch 58/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 1.0000\n","Epoch 59/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 1.0000\n","Epoch 60/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0187 - accuracy: 0.9990\n","Epoch 61/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0180 - accuracy: 1.0000\n","Epoch 62/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 1.0000\n","Epoch 63/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0173 - accuracy: 1.0000\n","Epoch 64/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 1.0000\n","Epoch 65/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0145 - accuracy: 0.9990\n","Epoch 66/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 1.0000\n","Epoch 67/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 1.0000\n","Epoch 68/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0152 - accuracy: 1.0000\n","Epoch 69/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 1.0000\n","Epoch 70/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0117 - accuracy: 1.0000\n","Epoch 71/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0145 - accuracy: 1.0000\n","Epoch 72/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0125 - accuracy: 1.0000\n","Epoch 73/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 1.0000\n","Epoch 74/100\n","32/32 [==============================] - 1s 24ms/step - loss: 0.0123 - accuracy: 0.9990\n","Epoch 75/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 1.0000\n","Epoch 76/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0097 - accuracy: 1.0000\n","Epoch 77/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0096 - accuracy: 1.0000\n","Epoch 78/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 1.0000\n","Epoch 79/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 1.0000\n","Epoch 80/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0088 - accuracy: 1.0000\n","Epoch 81/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 1.0000\n","Epoch 82/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 1.0000\n","Epoch 83/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 1.0000\n","Epoch 84/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0067 - accuracy: 1.0000\n","Epoch 85/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000\n","Epoch 86/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 1.0000\n","Epoch 87/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 1.0000\n","Epoch 88/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 89/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 1.0000\n","Epoch 90/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 1.0000\n","Epoch 91/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 1.0000\n","Epoch 92/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 93/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 94/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000\n","Epoch 95/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 96/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 97/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 1.0000\n","Epoch 98/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 99/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 100/100\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0039 - accuracy: 1.0000\n"]}]},{"cell_type":"code","source":["# 100 epochs\n","model.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRnaGyNKkTd0","executionInfo":{"status":"ok","timestamp":1651333868185,"user_tz":240,"elapsed":472,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"564ba24d-7408-4f33-f59a-d05693d84650"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["14/14 [==============================] - 0s 6ms/step - loss: 3.0351 - accuracy: 0.4687\n"]},{"output_type":"execute_result","data":{"text/plain":["[3.035072088241577, 0.46867749094963074]"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["ans = model.predict(test_dataset)"],"metadata":{"id":"BZKuFfl_lEhL","executionInfo":{"status":"ok","timestamp":1651333868186,"user_tz":240,"elapsed":17,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["ans[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJmCS0PJmQ91","executionInfo":{"status":"ok","timestamp":1651333868186,"user_tz":240,"elapsed":16,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"b9e24951-3605-449e-8af5-39c40549d951"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20,)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["y_test[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zM4g8D2m2xO","executionInfo":{"status":"ok","timestamp":1651333868187,"user_tz":240,"elapsed":13,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"c42aaad8-cc8d-4b72-b75c-869678ddfd49"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0.], dtype=float32)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["print(accuracy_score(y_test, np_utils.to_categorical(np.argmax(ans,axis=1))))\n","print(classification_report(y_test, np_utils.to_categorical(np.argmax(ans,axis=1))),)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5-fxTPKnEBc","executionInfo":{"status":"ok","timestamp":1651333868187,"user_tz":240,"elapsed":9,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"f96958cf-404d-4910-a271-f805626b85d5"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["0.46867749419953597\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         2\n","           1       0.00      0.00      0.00         7\n","           2       0.27      0.15      0.20        26\n","           3       0.38      0.23      0.29        13\n","           4       0.52      0.70      0.59        23\n","           5       0.00      0.00      0.00         2\n","           6       0.57      0.45      0.50        38\n","           7       0.49      0.46      0.48        41\n","           8       0.25      0.14      0.18         7\n","           9       0.50      0.50      0.50         4\n","          10       0.00      0.00      0.00         8\n","          11       0.61      0.63      0.62        84\n","          12       0.82      0.75      0.78        12\n","          13       0.44      0.59      0.50        44\n","          14       0.31      0.33      0.32        46\n","          15       0.35      0.53      0.42        40\n","          16       0.71      0.67      0.69        15\n","          17       0.00      0.00      0.00         3\n","          18       0.33      0.27      0.30        11\n","          19       1.00      0.20      0.33         5\n","\n","   micro avg       0.47      0.47      0.47       431\n","   macro avg       0.43      0.38      0.38       431\n","weighted avg       0.46      0.47      0.46       431\n"," samples avg       0.47      0.47      0.47       431\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["np_utils.to_categorical(np.argmax(ans[:2],axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dMu3KH2RlKgF","executionInfo":{"status":"ok","timestamp":1651307720266,"user_tz":240,"elapsed":131,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"58908537-2d02-450b-a66d-c4dd709ba99b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","        0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 1.]], dtype=float32)"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["# 10 epochs\n","model.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_IzcSpDj7tU","executionInfo":{"status":"ok","timestamp":1651306908031,"user_tz":240,"elapsed":325,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"ef2aa982-a488-45bc-8f34-66d1948110ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["14/14 [==============================] - 0s 3ms/step - loss: 1.8786 - accuracy: 0.4130\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.8785860538482666, 0.41299304366111755]"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["result = model.fit(values, Y_train[:400],\n","                    epochs=2, batch_size=32,\n","                    verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"BIBc1qFCo3Mo","executionInfo":{"status":"error","timestamp":1651303362829,"user_tz":240,"elapsed":313,"user":{"displayName":"Keanu Nichols","userId":"15455753636681602329"}},"outputId":"bd8e05b4-65cf-4067-f31b-96568681e7de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-5be2f91cad7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m result = model.fit(values, Y_train[:400],\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     verbose=1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m   raise TypeError(f\"Cannot convert the argument `type_value`: {type_value!r} \"\n\u001b[0m\u001b[1;32m    722\u001b[0m                   \"to a TensorFlow DType.\")\n","\u001b[0;31mTypeError\u001b[0m: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType."]}]},{"cell_type":"markdown","source":["https://austingwalters.com/classify-sentences-via-a-multilayer-perceptron-mlp/\n","https://github.com/holbertonschool/deep-learning/blob/master/Class%20%233/Text%20Classification%20MLP%20Reuters%20Dataset.ipynb\n","https://towardsdatascience.com/text-classification-with-extremely-small-datasets-333d322caee2\n","\n","\n","Hidden state (embeddings):\n","https://github.com/huggingface/transformers/issues/1950"],"metadata":{"id":"6fJxfhEyrzqu"}}],"metadata":{"colab":{"name":"MD5_1_English.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}