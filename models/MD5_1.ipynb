{"cells":[{"cell_type":"code","execution_count":97,"metadata":{"id":"xfFt0u5OQXrs","executionInfo":{"status":"ok","timestamp":1651308089700,"user_tz":240,"elapsed":153,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"outputs":[],"source":["import os\n","import csv\n","import json\n","import logging\n","import math\n","from typing import List, Dict, Tuple, Callable, Iterable, Optional, Any\n","\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import pickle\n","import numpy as np\n","from keras.utils import np_utils\n","from sklearn.preprocessing import LabelEncoder\n","from numpy import save\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.metrics import classification_report\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":864,"status":"ok","timestamp":1651305717931,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"},"user_tz":240},"id":"qF3gDP8cRzCI","outputId":"17672ca0-2d5a-429c-ddd0-0fe59b26323b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","folder_ = 'drive/MyDrive/Masters/Year_1/Semester_2/CS_505/Project/'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19716,"status":"ok","timestamp":1651305737644,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"},"user_tz":240},"id":"jYn8iNg-Q9f4","outputId":"ad575080-5052-460e-ac6c-d564b94a2889"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.5.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.96)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.12.0+cu113)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.18.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.11.0+cu113)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (4.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.49)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.8.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"]}],"source":["!pip install transformers\n","!pip install sentence_transformers"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zLo6wg4XRBPV","executionInfo":{"status":"ok","timestamp":1651305740127,"user_tz":240,"elapsed":2487,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"outputs":[],"source":["from sentence_transformers import SentenceTransformer, models, InputExample, losses\n","from sentence_transformers.evaluation import LabelAccuracyEvaluator, SentenceEvaluator\n","from sentence_transformers.util import batch_to_device\n","from torch import Tensor\n","from torch.utils.data import DataLoader\n","from transformers import MT5EncoderModel, AutoConfig,T5Tokenizer\n","from transformers import pipeline, AutoTokenizer"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ymk91t-DWStx","executionInfo":{"status":"ok","timestamp":1651305740128,"user_tz":240,"elapsed":5,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"outputs":[],"source":["train_df=pd.read_csv(folder_ + 'Data/Train.csv')\n","#test_df=pd.read_csv('C:/Users/leose/second_semester/NLP/malawi_news_classification/data/test.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"a3w1gF-dWc_4","executionInfo":{"status":"ok","timestamp":1651305740128,"user_tz":240,"elapsed":4,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"outputs":[],"source":["train_df['Text']=train_df['Text'].tolist()\n","#test_df['Text']=test_df['Text'].tolist()\n","train_batch_sentences=[]\n","#test_batch_sentences=[]\n","\n","#for frame in train_df['Text']:\n","#    train_batch_sentences.append(frame)\n","#for sentence in test_df['Text']:\n","#    test_batch_sentences.append(frame)"]},{"cell_type":"code","source":["len(train_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2ka1QlWfkgH","executionInfo":{"status":"ok","timestamp":1651305765512,"user_tz":240,"elapsed":152,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"2372fb9d-7ecb-4746-f5e5-b816a18501d8"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1436"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["model = MT5EncoderModel.from_pretrained(\"google/mt5-small\")\n","tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-small\")\n","#article = \"UN Offizier sagt, dass weiter verhandelt werden muss in Syrien.\"\n","#for sentence\n","#input_ids = tokenizer(train_batch_sentences[0], return_tensors=\"pt\",truncation=True,max_length=512).input_ids\n","#outputs = model(input_ids)\n","#hidden_state = outputs.last_hidden_state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAc27pTVgsMm","executionInfo":{"status":"ok","timestamp":1651305750076,"user_tz":240,"elapsed":9952,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"e5fe21f3-e5ed-407d-c8e4-9f73adb03607"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/mt5-small were not used when initializing MT5EncoderModel: ['decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.final_layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.embed_tokens.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'lm_head.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight']\n","- This IS expected if you are initializing MT5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing MT5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["print(len(train_df[1200:]))\n","print(len(train_df[1200:len(train_df)]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1COtRkQmfn-g","executionInfo":{"status":"ok","timestamp":1651305851405,"user_tz":240,"elapsed":153,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"0301a997-d9e0-4561-9b47-bf8f4d2b64c9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["236\n","236\n"]}]},{"cell_type":"code","source":["input_ids = []\n","#for frame in train_df['Text'][:400]:\n","lower = 1200\n","#upper = lower+400\n","upper = len(train_df)\n","for frame in train_df['Text'][lower:upper]:\n","    input_ids.append(tokenizer(frame, return_tensors=\"pt\",truncation=True,max_length=64).input_ids)\n","\n","outputs = []\n","for input_ in input_ids:\n","  outputs.append(model(input_))\n","\n","hidden_state = []\n","for output_ in outputs:\n","  hidden_state.append(output_.last_hidden_state)\n","\n","values = torch.zeros((400,512))\n","for i in range(len(hidden_state)):\n","  values[i] = (torch.mean(hidden_state[i][0],axis=0))\n","\n","#save(folder_ + 'Data/' + 'data_400_800.npy', values.detach().numpy())\n","\n","save(folder_ + 'Data/' + 'data_' + str(lower) + '_' + str(upper) + '.npy', values.detach().numpy())"],"metadata":{"id":"9iT6nee9lWf8","executionInfo":{"status":"ok","timestamp":1651305891301,"user_tz":240,"elapsed":19670,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["len(input_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRP4l-gMiKyU","executionInfo":{"status":"ok","timestamp":1651304848352,"user_tz":240,"elapsed":131,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"028e235f-de18-467a-e849-69191db7fa2f"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["600"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["lower = 0\n","upper = lower+400"],"metadata":{"id":"AOIEtKX4geu4","executionInfo":{"status":"ok","timestamp":1651306011986,"user_tz":240,"elapsed":200,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["li[3][236]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rV4qTBluiNpC","executionInfo":{"status":"ok","timestamp":1651306511066,"user_tz":240,"elapsed":176,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"bbc4d86f-1457-47a9-db32-b61b836e60d4"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0.], dtype=float32)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["lower = 0\n","upper = lower+400\n","li = []\n","for i in range(4):\n","  arr = np.load(folder_ + 'Data/' + 'data_' + str(lower) + '_' + str(upper) + '.npy')\n","  li.append(arr)\n","  lower+=400\n","  upper+=400\n","  if(lower == 1200):\n","    upper = 1436\n","  #break"],"metadata":{"id":"iqJWgCLOgT6n","executionInfo":{"status":"ok","timestamp":1651306331798,"user_tz":240,"elapsed":155,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["final_arr = np.vstack((li[0],li[1],li[2],li[3]))\n","final_arr = final_arr[:1436]"],"metadata":{"id":"wwHmDXLuh1Zl","executionInfo":{"status":"ok","timestamp":1651306676624,"user_tz":240,"elapsed":135,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["final_arr.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oL3annwaiB0q","executionInfo":{"status":"ok","timestamp":1651306678097,"user_tz":240,"elapsed":1,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"e47af8d6-d76c-44d5-94bb-17757208c6f7"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1436, 512)"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["final_arr[1435]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fE9lGXdeijgp","executionInfo":{"status":"ok","timestamp":1651306682562,"user_tz":240,"elapsed":165,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"c59ced6f-420b-4c7c-bc6a-c2bd2a5cb0d1"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-5.26638143e-02, -1.54549867e-01,  1.86291840e-02, -1.83572739e-01,\n","       -7.87804574e-02,  5.09037301e-02,  2.03488126e-01,  3.10577769e-02,\n","       -2.82362122e-02, -4.99501117e-02,  2.41595507e-01, -1.40947133e-01,\n","        3.49488258e-02, -1.30859837e-01,  6.62851632e-02, -8.03611204e-02,\n","       -1.00439146e-01, -3.87492739e-02, -8.31745118e-02,  6.70289844e-02,\n","        2.66414620e-02,  1.25922114e-01, -8.44994038e-02,  5.71737066e-02,\n","       -3.76449794e-01,  2.24952493e-02, -8.02223682e-01,  2.64139920e-02,\n","        9.43697542e-02,  1.39501467e-01,  6.02034554e-02,  9.61242914e-02,\n","       -1.40072122e-01, -8.43710750e-02,  2.26025637e-02,  8.08138996e-02,\n","       -6.60696030e-02,  1.28506556e-01,  3.32188196e-02, -2.54327714e-01,\n","        1.76303789e-01, -9.96564031e-02, -1.18747167e-01,  9.18802321e-02,\n","        9.74093527e-02, -1.41530484e-01,  8.24178755e-02, -1.24160178e-01,\n","        5.84548041e-02, -2.65140980e-02, -1.03624135e-01, -2.03897849e-01,\n","       -2.53316015e-02,  3.19525480e-01,  8.95995796e-02,  3.45133618e-02,\n","       -1.37856722e-01,  9.99978706e-02,  5.43730818e-02,  1.15518764e-01,\n","        5.23590483e-02, -5.62424026e-02,  1.46161437e-01,  2.01299518e-01,\n","       -7.15736579e-03, -8.16713572e-02, -1.32829517e-01,  6.61594942e-02,\n","        2.15490498e-02,  1.00259408e-01,  5.52325025e-02,  5.44385836e-02,\n","       -1.95129633e-01, -3.28413695e-02,  3.12885195e-01,  6.94027692e-02,\n","        2.03671426e-01,  1.92085534e-01,  1.26195308e-02, -4.64701131e-02,\n","       -7.73701146e-02,  5.27003556e-02, -1.45031184e-01,  1.51025683e-01,\n","        1.64008886e-03,  1.72960922e-01, -2.12891996e-01, -9.85172242e-02,\n","       -1.20727442e-01, -1.14161044e-01,  2.65220046e-01,  1.65285245e-01,\n","        4.34007309e-03,  5.66615164e-02,  1.51842207e-01, -4.16501015e-02,\n","       -7.58082978e-03, -6.46937732e-03,  2.07331423e-02, -7.26304278e-02,\n","        1.23031372e-02,  9.20572728e-02,  7.35855252e-02, -4.40784395e-02,\n","       -6.03277236e-03,  1.52477100e-01, -2.13034958e-01, -1.66834183e-02,\n","        6.35157228e-02, -3.59152444e-03,  1.84002630e-02, -7.40803964e-03,\n","        1.21420987e-01, -6.83190078e-02,  3.66696157e-02, -3.51688676e-02,\n","       -5.85225262e-02, -1.37004312e-02, -1.14075996e-01, -1.82566762e-01,\n","        1.36644945e-01,  1.30314931e-01, -9.69058573e-02, -1.07021788e-02,\n","        9.94865522e-02, -5.63222617e-02, -1.31119132e-01,  3.76661792e-02,\n","        8.12636390e-02, -3.05430554e-02,  8.36031511e-02, -9.83496010e-03,\n","        1.30291674e-02,  2.65807152e-01, -2.00400233e-01, -1.53203644e-02,\n","        5.37604466e-02,  4.66570184e-02, -1.65600583e-01, -5.75195998e-02,\n","        7.67391026e-02,  4.28453535e-02,  2.07444131e-01,  3.70600335e-02,\n","        4.19520810e-02, -7.84106851e-02,  1.78685989e-02,  4.97287437e-02,\n","       -1.70424543e-02, -4.85331006e-02,  1.27713839e-02,  1.60920009e-01,\n","        6.67521134e-02, -7.45074078e-02,  1.89169675e-01,  1.99192479e-01,\n","        2.28387490e-02,  4.15583923e-02, -2.34091133e-02,  1.07122943e-01,\n","       -1.02412179e-01,  2.28151716e-02,  4.73674685e-02,  1.90203637e-03,\n","       -8.77431184e-02, -7.28843659e-02, -6.36630207e-02, -1.08255912e-02,\n","       -1.59330815e-01,  6.12560175e-02,  4.34848666e-01, -1.06545016e-01,\n","       -1.66681617e-01,  1.51762575e-01, -5.64533994e-02,  1.93678252e-02,\n","        5.98113611e-02,  6.07514009e-03,  6.87266588e-02,  2.84647495e-02,\n","       -1.22467391e-02, -1.25998631e-01, -2.20204070e-01, -8.81007984e-02,\n","       -9.03305560e-02,  2.94103742e-01,  1.01368539e-01, -1.86778046e-03,\n","        3.37035693e-02,  2.02132255e-01, -8.07272643e-02,  1.48600519e-01,\n","        1.08908474e-01, -3.59218102e-03,  4.38558422e-02, -8.02270398e-02,\n","        1.63984746e-02,  4.64711748e-02, -1.52805135e-01,  9.86678302e-02,\n","       -9.24151614e-02,  1.03457533e-01, -4.88512181e-02,  1.03919640e-01,\n","        1.00135893e-01, -4.04176749e-02,  1.32232890e-01,  3.06031585e-01,\n","       -2.97685236e-01, -2.87916735e-02,  1.16827473e-01,  6.02365434e-02,\n","        1.25803038e-01,  4.68919352e-02, -2.27374583e-01, -1.34950895e-02,\n","       -2.30651319e-01,  3.47336419e-02,  1.56002924e-01, -1.81914613e-01,\n","       -1.43585624e-02, -2.75655501e-02,  1.16235159e-01, -1.60535723e-01,\n","        2.84683853e-02,  6.01115115e-02, -1.68739166e-03, -5.14156669e-02,\n","        1.59820560e-02, -8.68215561e-02, -7.73929805e-02,  6.84751496e-02,\n","       -6.19345009e-02, -2.93068141e-01,  1.83482066e-01, -2.52257109e-01,\n","       -1.83050185e-02, -1.53688312e-01, -9.98862311e-02,  2.61963531e-02,\n","       -6.82485104e-02,  1.45700285e-02,  3.63601670e-02,  1.29102349e-01,\n","       -8.45860243e-02,  4.09019366e-02,  9.14121643e-02,  8.89118947e-03,\n","        7.64350593e-02,  3.96740511e-02,  5.80817126e-02,  2.19590038e-01,\n","       -2.43964270e-01, -1.23355463e-01, -1.49499893e-01,  1.05336169e-02,\n","       -2.54373066e-03, -1.23659506e-01, -1.53258219e-01,  1.39171094e-01,\n","        2.39410978e-02, -1.59908965e-01,  1.36237696e-01,  2.66771559e-02,\n","        5.70354685e-02, -1.16055697e-01,  1.10642374e-01,  1.63493365e-01,\n","        9.12906602e-02,  2.01230645e-01,  6.11539446e-02,  6.15969673e-02,\n","       -1.04372859e-01,  1.31315917e-01, -1.91992998e-01, -8.64006877e-02,\n","       -1.92857385e-01, -2.56903712e-02,  4.95558605e-02,  5.12255095e-02,\n","        7.83499777e-02,  9.77366269e-02, -1.00987814e-02,  7.61512816e-02,\n","       -4.84074503e-02, -1.15997344e-01,  7.08467811e-02, -9.45090204e-02,\n","       -1.16377428e-01, -1.14510864e-01,  9.95045155e-02, -1.56261802e-01,\n","        1.40327007e-01,  1.25478934e-02, -4.12145965e-02,  6.60455525e-02,\n","       -2.35514268e-01,  2.03866243e-01, -1.29009470e-01, -8.80269855e-02,\n","        2.72480100e-02,  1.60330296e-01, -1.00368291e-01,  2.52620071e-01,\n","        5.35425656e-02, -1.31280348e-03,  3.82950157e-02,  9.25519466e-02,\n","       -1.31841674e-02,  7.01957345e-02, -9.06717852e-02, -6.84394389e-02,\n","        8.25576112e-02,  1.17681101e-01, -1.03465356e-01, -2.04246610e-01,\n","       -1.39979869e-01,  1.03539132e-01,  2.58387148e-01,  2.60101289e-01,\n","       -3.85038666e-02,  1.17744684e-01,  1.56042695e-01,  6.72942325e-02,\n","        1.47902772e-01, -1.85423158e-02,  1.11114793e-01, -2.01154470e-01,\n","        1.81593984e-01, -2.14856155e-02,  1.75494567e-01,  4.51606996e-02,\n","        1.62038490e-01,  2.18230695e-01, -9.11282718e-01,  6.09733909e-02,\n","        2.58296102e-01,  1.04662806e-01,  1.78261131e-01, -8.99904501e-03,\n","        5.75225055e-03, -2.64490426e-01, -4.83387057e-03, -1.38247889e-02,\n","        3.31332907e-03,  1.04151890e-01,  3.86089757e-02, -1.00115083e-01,\n","        1.32713541e-01, -8.00608322e-02, -9.05360058e-02,  1.52382940e-01,\n","        4.24793288e-02,  1.16402462e-01, -6.76897615e-02, -2.03461736e-01,\n","       -1.25644267e-01, -7.70081878e-02, -8.02530125e-02, -5.21805063e-02,\n","       -1.66667461e-01, -1.96932349e-02,  3.61401401e-02, -4.33397852e-02,\n","        5.34897633e-02,  7.03781173e-02, -8.45212787e-02, -1.36547163e-02,\n","       -4.32205275e-02,  1.50603354e-01,  8.33128393e-02, -4.43487689e-02,\n","       -2.11007595e-01,  1.18032731e-02,  6.38430864e-02,  1.02490187e-01,\n","        2.39510000e-01,  2.81302370e-02, -1.34560719e-01, -5.83842099e-02,\n","        1.92560226e-01,  1.25440568e-01,  2.11941469e-02, -1.32612493e-02,\n","        1.47220075e-01, -2.31947042e-02,  1.46421399e-02, -2.49647066e-01,\n","       -1.54333144e-01,  1.49464041e-01, -5.03290966e-02,  1.10406011e-01,\n","       -1.32251889e-01,  1.13028467e-01,  2.24649087e-02, -3.72478627e-02,\n","        1.79788977e-01, -2.99319867e-02,  3.63363698e-02, -9.70552266e-02,\n","       -3.80267292e-01,  1.75725758e-01, -7.84628093e-04, -6.43532872e-02,\n","       -1.10025331e-03, -4.60098758e-02, -5.97702041e-02,  2.74307281e-01,\n","        9.14940238e-02,  1.98515058e-01,  1.10981666e-01,  2.66756788e-02,\n","        9.95992571e-02,  2.65155584e-01, -1.88547015e-01,  5.70510477e-02,\n","        6.80383295e-02, -9.27495677e-03, -6.88922033e-03, -2.84931622e-03,\n","        1.26089573e-01, -2.85950541e-01, -7.02556968e-02, -6.54159114e-02,\n","        1.93061128e-01, -1.14788674e-03, -2.33587861e-01, -2.57853061e-01,\n","        3.30265760e-02, -1.29136115e-01,  9.29212198e-02,  5.95380217e-02,\n","       -3.41211110e-02, -4.38082181e-02, -1.10919841e-01,  2.27427222e-02,\n","        8.65283012e-02,  2.88263828e-01, -9.83277149e-03, -1.58650801e-02,\n","       -2.82354858e-02, -8.66629630e-02, -4.69342954e-02,  9.25438106e-02,\n","       -7.49834068e-03,  3.00962292e-02,  7.72748441e-02, -1.08783871e-01,\n","       -1.15425050e+00,  6.89635798e-03,  2.16822222e-01,  4.65432927e-02,\n","        1.33184835e-01, -1.54873401e-01, -1.59638852e-01,  1.17132723e-01,\n","       -1.62228733e-01, -6.45145327e-02,  1.95824429e-02, -5.81652038e-02,\n","       -8.59958977e-02,  1.37422249e-01, -9.56564397e-02,  6.11605160e-02,\n","       -2.84923941e-01, -9.92775336e-02,  5.50487600e-02, -1.49312973e-01,\n","       -1.21408641e-01, -2.81025469e-03,  5.60866296e-03, -1.35805696e-01,\n","        1.44643247e-01, -7.28355423e-02, -1.95351243e-01,  7.34647550e-03,\n","        1.15119711e-01, -3.65398318e-01,  1.15840919e-02,  9.65188891e-02,\n","       -8.28015655e-02, -1.09136909e-01, -5.30389994e-02, -8.45767260e-02,\n","        4.41003777e-02,  1.09006256e-01, -7.37665892e-02,  3.83598357e-02,\n","        1.42098874e-01,  9.62611958e-02,  1.54669389e-01,  2.07591131e-02,\n","        4.86616045e-04,  4.73585725e-01,  1.09629884e-01, -5.68518676e-02,\n","       -1.12470478e-01,  9.79526192e-02, -1.45631433e-01, -3.64814065e-02,\n","       -5.41577339e-02,  1.30781218e-01,  1.01605915e-02,  4.57620472e-01,\n","       -1.81682751e-01, -7.14427680e-02,  2.77616009e-02, -8.93072337e-02,\n","       -4.32648398e-02, -8.62880237e-03, -2.13946737e-02,  5.90836257e-02],\n","      dtype=float32)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["len(li)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11-gytt6hwOq","executionInfo":{"status":"ok","timestamp":1651306338629,"user_tz":240,"elapsed":8,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"eb710d2a-fd91-478a-e617-a3aa4090a752"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["print(upper)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnyw-odche7T","executionInfo":{"status":"ok","timestamp":1651306268359,"user_tz":240,"elapsed":173,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"51e93374-23eb-4986-8574-92118adc390d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["400\n"]}]},{"cell_type":"code","source":["li[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDtXB4oOgivA","executionInfo":{"status":"ok","timestamp":1651306073363,"user_tz":240,"elapsed":158,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"bf8b7e9a-8ebd-4e3f-95f2-02513be0231c"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(400, 512)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["arr[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TfT7h4ucgkLN","executionInfo":{"status":"ok","timestamp":1651306023651,"user_tz":240,"elapsed":3,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"0c35ffaa-de6a-4fc8-961c-21892ce615d6"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 7.08791763e-02, -2.02946827e-01, -1.56982150e-02, -2.34370932e-01,\n","       -1.09996378e-01,  2.73883110e-03,  1.57767594e-01, -1.20873973e-01,\n","        2.68560164e-02, -1.57486871e-01,  1.85399428e-01,  3.01670600e-02,\n","       -1.16110876e-01, -8.03325027e-02,  1.04789004e-01,  4.00744490e-02,\n","       -9.64827463e-03,  7.80769512e-02, -6.54094592e-02,  2.34272540e-01,\n","        9.03735012e-02,  1.47255048e-01, -2.97365904e-01, -3.12710879e-04,\n","       -4.81514990e-01,  3.51317227e-04, -7.38334060e-01, -2.45272331e-02,\n","        1.21216420e-02,  2.32545480e-01,  2.31464505e-02,  9.60460082e-02,\n","       -9.67335105e-02,  2.14932412e-02, -4.95644957e-02,  3.85352559e-02,\n","        6.06095046e-02,  2.17731535e-01,  1.56561822e-01, -2.69394934e-01,\n","        1.49119318e-01, -1.62100509e-01, -6.88991696e-02, -3.04846093e-02,\n","        3.67550701e-02, -1.43635780e-01,  6.77190796e-02,  8.12766477e-02,\n","       -9.13721398e-02, -6.80922195e-02, -1.08639903e-01, -1.19903527e-01,\n","       -3.17084938e-02,  2.11318880e-01, -3.55856754e-02,  1.77221715e-01,\n","       -6.95642754e-02,  7.61901289e-02,  8.00413713e-02,  2.07410112e-01,\n","        4.96075228e-02, -9.82541740e-02,  2.12752074e-01,  2.57093549e-01,\n","        3.80316600e-02,  1.42215937e-01,  3.76908556e-02,  1.64133087e-01,\n","        3.27262282e-02,  5.09085655e-02,  1.32421330e-02, -1.17963403e-02,\n","        1.79832168e-02, -1.46847904e-01,  2.27661341e-01,  5.55189252e-02,\n","        6.65876195e-02,  4.49504927e-02,  7.61391968e-02, -4.13952060e-02,\n","        3.80135104e-02,  2.65107840e-01, -6.97489828e-02,  2.62788057e-01,\n","       -1.08198598e-02,  2.50104100e-01, -1.15851551e-01, -6.81722462e-02,\n","       -1.31775454e-01, -9.61680263e-02,  1.47852108e-01,  8.89527351e-02,\n","       -8.89699906e-03,  2.45290753e-02,  6.36296645e-02, -2.76362952e-02,\n","       -1.16701424e-01,  1.27636775e-01, -2.07263585e-02,  2.02626996e-02,\n","        1.01060197e-01,  1.17762491e-01, -9.58089530e-03, -1.36756763e-01,\n","       -9.37701017e-02,  2.04017639e-01, -2.25755289e-01,  7.05001950e-02,\n","       -3.15297954e-03, -4.61750366e-02,  4.08815220e-03, -8.61280486e-02,\n","        1.41845316e-01, -8.29120129e-02,  6.11836128e-02, -8.19006860e-02,\n","       -1.76953003e-01, -6.21400252e-02,  1.42762754e-02, -1.80324987e-01,\n","        2.87696779e-01,  1.02253705e-01, -3.30983289e-02, -5.28015196e-02,\n","        1.09415457e-01, -5.04471958e-02, -7.89292157e-02,  6.41060621e-02,\n","        5.07378876e-02,  7.16639906e-02,  3.93414944e-02, -1.12594217e-01,\n","        1.17047809e-01,  2.13480234e-01, -3.29578817e-02,  5.33769690e-02,\n","        2.37039495e-02,  1.00258820e-01, -1.53892308e-01, -6.50493428e-02,\n","        5.48784994e-02,  4.28363718e-02,  1.78954899e-01, -3.26797552e-03,\n","       -5.17142415e-02, -3.69479507e-02,  6.73131943e-02,  7.08160698e-02,\n","        4.14878726e-02, -1.15683116e-01,  6.31768163e-03,  9.13187861e-04,\n","       -1.39050454e-01, -5.42984009e-02,  1.37674287e-01,  2.12739080e-01,\n","        5.88769317e-02,  4.80191708e-02, -1.59696177e-01,  1.41863525e-01,\n","       -1.59379557e-01, -8.54623690e-02,  2.15951025e-01,  1.36230275e-01,\n","       -1.65982619e-01,  2.36794911e-02, -1.25414521e-01,  5.48689887e-02,\n","        2.35336199e-02,  5.56043200e-02,  8.87864172e-01,  1.21638924e-03,\n","       -1.96203902e-01,  2.33937770e-01, -1.14533715e-02, -8.05486739e-02,\n","       -3.27724069e-02, -6.14452511e-02, -9.47560444e-02, -6.02221712e-02,\n","       -9.73242596e-02, -1.00673527e-01, -1.19780228e-01, -4.33782823e-02,\n","       -7.10545853e-03,  8.80994201e-02,  1.21055335e-01, -7.85272494e-02,\n","       -9.58272815e-03,  1.99686721e-01,  2.10676342e-04,  4.20821756e-02,\n","        3.39917317e-02, -1.88239738e-02,  4.25489880e-02, -1.08614489e-01,\n","       -1.37101889e-01,  1.50686696e-01, -9.11724269e-02,  4.11027446e-02,\n","       -8.46518762e-03, -3.10532190e-03, -1.60656214e-01,  7.57910311e-02,\n","        2.25180998e-01, -4.38366644e-03,  1.62382275e-02,  1.86398610e-01,\n","       -1.27532527e-01, -2.11204588e-01,  4.48003300e-02, -3.78039628e-02,\n","        1.36726290e-01, -7.50792250e-02, -2.05884427e-01, -3.67915295e-02,\n","       -2.37368912e-01, -3.11509520e-02,  1.09088883e-01, -6.62215278e-02,\n","        1.39885750e-02, -3.28056142e-02,  1.80861428e-01, -1.86311960e-01,\n","        6.72331154e-02, -5.28236106e-03, -4.63649407e-02,  6.79207966e-04,\n","       -2.10558139e-02, -8.65048170e-02, -2.03611463e-01,  1.55940494e-02,\n","       -1.49881259e-01, -1.15707353e-01,  1.37110949e-01, -1.20626375e-01,\n","       -3.71624827e-02,  7.23627629e-03,  8.48194771e-03,  4.89499718e-02,\n","       -1.79390647e-02,  6.42953254e-03, -1.00720495e-01,  4.45760749e-02,\n","        3.49282660e-03,  8.92386213e-02, -3.68460827e-02, -5.46845645e-02,\n","        8.22735429e-02,  4.01620567e-02,  4.65582777e-03,  2.19749197e-01,\n","       -3.16949725e-01, -8.91767815e-02,  7.73324966e-02, -5.93449175e-02,\n","        8.02884772e-02,  7.12496936e-02, -5.83588891e-03,  3.90277915e-02,\n","        2.16694325e-02,  3.10848020e-02,  4.56882156e-02,  5.12061417e-02,\n","       -2.87188366e-02, -1.45821437e-01,  1.62576899e-01,  8.16658065e-02,\n","        7.43094832e-02,  2.31974781e-01,  7.53129125e-02,  1.15499213e-01,\n","       -1.23556770e-01,  9.89555642e-02, -1.32964835e-01, -5.73304258e-02,\n","       -1.39126122e-01, -4.72063944e-03,  4.14029732e-02,  1.14531085e-01,\n","        9.19317976e-02, -1.66217461e-02,  2.96597481e-02,  8.83182362e-02,\n","       -8.77541006e-02,  4.66617383e-03, -2.77787074e-03, -3.72547768e-02,\n","       -2.11833447e-01, -5.51849455e-02,  3.25195827e-02, -1.17927767e-01,\n","        6.72148094e-02, -1.40559077e-01,  5.90174496e-02,  8.27754512e-02,\n","       -1.14973031e-01,  6.57373965e-02, -4.93921936e-02, -2.93851972e-01,\n","        1.40299827e-01,  1.23528905e-01, -1.52177423e-01,  2.69977778e-01,\n","        6.11543134e-02,  1.32104099e-01,  8.12838450e-02,  9.56619605e-02,\n","       -7.14174360e-02, -5.39599732e-02,  2.37175077e-02, -2.38038540e-01,\n","        1.08513422e-01,  4.35672402e-02, -4.18753214e-02, -1.33774117e-01,\n","       -5.45560122e-02,  2.88977250e-02,  1.36006147e-01,  1.92191765e-01,\n","       -2.55080871e-02,  1.12198934e-01,  2.01842040e-01,  1.37173787e-01,\n","        1.71697699e-02, -1.05275169e-01,  7.83597082e-02, -2.11594075e-01,\n","        1.29656613e-01,  8.16508085e-02,  1.55293718e-01,  9.23539996e-02,\n","        2.04754412e-01,  6.69038594e-02, -9.11554992e-01,  6.01271391e-02,\n","        1.40066788e-01,  8.79875645e-02,  8.68509784e-02, -2.15288289e-02,\n","       -2.63898149e-02, -3.35543633e-01, -2.53151119e-01,  1.10012919e-01,\n","        2.17330176e-02,  1.56042874e-01, -4.31773104e-02, -1.48567423e-01,\n","       -6.73340634e-02, -1.21983588e-01, -8.56315419e-02,  1.61063671e-01,\n","       -6.55583218e-02,  8.45326483e-02,  9.74489897e-02, -2.18448594e-01,\n","       -9.12842825e-02,  2.51796935e-02, -5.95788769e-02,  1.29076570e-01,\n","       -9.00000706e-02,  8.21495429e-03,  4.68605496e-02,  6.33764267e-03,\n","       -6.77068383e-02,  5.67760430e-02, -9.43415314e-02,  9.57661718e-02,\n","       -1.19220959e-02,  1.16557360e-01, -1.89159326e-02, -6.70285523e-02,\n","       -2.42766410e-01,  2.10237540e-02, -3.98150682e-02,  5.03672808e-02,\n","        2.93687046e-01,  1.90502033e-03,  1.95375904e-02, -9.47832465e-02,\n","        7.81741962e-02, -3.04174051e-02, -7.61598721e-02,  9.60800946e-02,\n","        2.20184535e-01, -5.32457419e-02, -4.11726162e-03, -2.64906287e-01,\n","       -1.21543333e-01,  2.57624745e-01, -1.73792280e-02, -2.45596133e-02,\n","       -2.34105419e-02,  3.21971685e-01,  3.84245031e-02,  6.57671466e-02,\n","        1.85829073e-01,  8.12820718e-02, -2.32556835e-04, -1.02201357e-01,\n","       -1.74756721e-01,  1.42656267e-01,  5.09163365e-03, -5.32171279e-02,\n","       -1.24918312e-01, -7.04624429e-02,  1.12972163e-01,  1.74634069e-01,\n","       -1.07660912e-01, -5.91094140e-03,  6.93164915e-02,  1.15664110e-01,\n","        7.99516737e-02,  1.72608778e-01, -3.23824212e-02,  1.07993834e-01,\n","       -8.07820708e-02, -5.57812117e-03,  7.93968886e-02,  4.58230674e-02,\n","        4.71114218e-02, -3.18003893e-01, -2.87631247e-02,  1.45634478e-02,\n","        1.44564003e-01,  9.86831412e-02, -8.62815976e-02, -1.99332416e-01,\n","        1.08600378e-01, -8.39442685e-02, -6.09518364e-02,  8.37749615e-02,\n","       -7.27725103e-02,  1.49875609e-02, -1.68793470e-01, -3.65913808e-02,\n","       -5.50148934e-02,  1.86301902e-01, -1.11014489e-02, -1.09943360e-01,\n","        1.66347958e-02, -1.72920644e-01,  3.23115960e-02,  3.38242128e-02,\n","       -3.20276581e-02,  3.70330811e-02,  1.20766118e-01,  5.36869280e-04,\n","       -1.24871194e+00,  1.03303500e-01,  7.11161941e-02,  6.06127456e-03,\n","        9.95361358e-02,  1.76766664e-02, -2.04284668e-01,  1.38933077e-01,\n","       -1.44182622e-01, -3.72420661e-02, -8.05327445e-02, -1.16769075e-01,\n","       -2.75697634e-02, -2.16094833e-02, -4.14784402e-02,  1.52538031e-01,\n","       -1.53941482e-01, -1.79886162e-01, -3.54897603e-03, -2.09545255e-01,\n","       -2.75538921e-01, -6.33972734e-02, -9.25119743e-02,  8.70504379e-02,\n","        1.48227289e-01,  5.67437895e-03, -1.82465911e-01,  5.17198257e-03,\n","        1.13199607e-01, -1.38063297e-01, -7.29967207e-02,  5.24419472e-02,\n","       -9.15469825e-02, -1.14216752e-01,  6.48887902e-02, -4.24923152e-02,\n","       -2.59109586e-03,  8.09799284e-02,  6.57142550e-02,  8.40399601e-03,\n","        8.19958597e-02, -9.97187793e-02, -2.00258326e-02, -3.25423777e-02,\n","        9.09213163e-03,  2.91656703e-01,  1.44660473e-01, -1.95458710e-01,\n","       -1.14348732e-01,  5.14477231e-02, -9.40121859e-02,  5.56764007e-03,\n","        2.28264574e-02,  8.32905248e-03, -1.63634568e-02,  4.50375617e-01,\n","       -8.68672729e-02, -9.15767625e-02,  5.22731431e-03, -2.24749789e-01,\n","       -9.22554135e-02, -1.35976207e-02,  1.14541456e-01, -5.99570423e-02],\n","      dtype=float32)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["np.unique(train_df['Label']).shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSeJZ_5pne4Y","executionInfo":{"status":"ok","timestamp":1651304034795,"user_tz":240,"elapsed":136,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"41ea0828-5a6c-465e-f7d4-0835e24c9f87"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["le = LabelEncoder()\n","train_df.Label = le.fit_transform(train_df.Label)"],"metadata":{"id":"AghmKiVUoB7G","executionInfo":{"status":"ok","timestamp":1651306694708,"user_tz":240,"elapsed":146,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["Y_train = np_utils.to_categorical(train_df['Label'], np.unique(train_df['Label']).shape[0])"],"metadata":{"id":"zbxR9sxTnO8t","executionInfo":{"status":"ok","timestamp":1651306696645,"user_tz":240,"elapsed":127,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["print(Y_train.shape)\n","print(Y_train[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YiNySUtzoH-O","executionInfo":{"status":"ok","timestamp":1651306698263,"user_tz":240,"elapsed":143,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"c8e1ede1-df21-4e95-f3d8-dd1b184ef862"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["(1436, 20)\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}]},{"cell_type":"code","source":["print('Building model...')\n","model = Sequential()\n","model.add(Dense(1024, input_shape=(512,)))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(20))\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#make one, takes in, double that amount, english and chichewa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZhUUJbJoQ_x","executionInfo":{"status":"ok","timestamp":1651306702117,"user_tz":240,"elapsed":519,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"78da8e1d-9664-4380-e151-d0cbecdd04aa"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Building model...\n"]}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RlXfKNP2oyPU","executionInfo":{"status":"ok","timestamp":1651306703852,"user_tz":240,"elapsed":156,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"01433bf5-7b05-4972-9a96-25f094600364"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 1024)              525312    \n","                                                                 \n"," activation (Activation)     (None, 1024)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 1024)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 20)                20500     \n","                                                                 \n"," activation_1 (Activation)   (None, 20)                0         \n","                                                                 \n","=================================================================\n","Total params: 545,812\n","Trainable params: 545,812\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(\n","        final_arr, Y_train, test_size=0.3, random_state=42, stratify=Y_train)"],"metadata":{"id":"NLzLqYgEjM0y","executionInfo":{"status":"ok","timestamp":1651306774461,"user_tz":240,"elapsed":149,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebg0U5ORjccQ","executionInfo":{"status":"ok","timestamp":1651306780243,"user_tz":240,"elapsed":157,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"34a9836f-b2c5-4794-c697-92a2f5d27163"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1005, 512)"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["y_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8zM6igJjeF2","executionInfo":{"status":"ok","timestamp":1651306805681,"user_tz":240,"elapsed":9,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"36e960b7-b499-421c-b269-18ab1fe9a130"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n","       0., 0., 0.], dtype=float32)"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["#train_dataset = tf.data.Dataset.from_tensor_slices((values.detach().numpy(), Y_train[:400]))\n","train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"],"metadata":{"id":"3y0MmA6cWxK2","executionInfo":{"status":"ok","timestamp":1651306879324,"user_tz":240,"elapsed":147,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"gdvG8KAVZNuP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 32\n","SHUFFLE_BUFFER_SIZE = 100\n","\n","train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","test_dataset = test_dataset.batch(BATCH_SIZE)"],"metadata":{"id":"0BFtZ67-XLN6","executionInfo":{"status":"ok","timestamp":1651306881287,"user_tz":240,"elapsed":139,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["result = model.fit(train_dataset,\n","                    epochs=100, batch_size=32,\n","                    verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJq_So_aW6X_","executionInfo":{"status":"ok","timestamp":1651308192706,"user_tz":240,"elapsed":28846,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"767859ba-bdc5-4c30-e9c9-b0658c58b102"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","32/32 [==============================] - 0s 9ms/step - loss: 0.3742 - accuracy: 0.9214\n","Epoch 2/100\n","32/32 [==============================] - 0s 8ms/step - loss: 0.3455 - accuracy: 0.9274\n","Epoch 3/100\n","32/32 [==============================] - 0s 9ms/step - loss: 0.3394 - accuracy: 0.9284\n","Epoch 4/100\n","32/32 [==============================] - 0s 9ms/step - loss: 0.3128 - accuracy: 0.9393\n","Epoch 5/100\n","32/32 [==============================] - 0s 9ms/step - loss: 0.3075 - accuracy: 0.9463\n","Epoch 6/100\n","32/32 [==============================] - 0s 8ms/step - loss: 0.2985 - accuracy: 0.9453\n","Epoch 7/100\n","32/32 [==============================] - 0s 10ms/step - loss: 0.2816 - accuracy: 0.9423\n","Epoch 8/100\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2758 - accuracy: 0.9512\n","Epoch 9/100\n","32/32 [==============================] - 0s 8ms/step - loss: 0.2616 - accuracy: 0.9582\n","Epoch 10/100\n","32/32 [==============================] - 0s 8ms/step - loss: 0.2488 - accuracy: 0.9542\n","Epoch 11/100\n","32/32 [==============================] - 0s 9ms/step - loss: 0.2235 - accuracy: 0.9672\n","Epoch 12/100\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2150 - accuracy: 0.9692\n","Epoch 13/100\n","32/32 [==============================] - 0s 13ms/step - loss: 0.2073 - accuracy: 0.9701\n","Epoch 14/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1863 - accuracy: 0.9771\n","Epoch 15/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1856 - accuracy: 0.9801\n","Epoch 16/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1715 - accuracy: 0.9871\n","Epoch 17/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1649 - accuracy: 0.9801\n","Epoch 18/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1593 - accuracy: 0.9881\n","Epoch 19/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1606 - accuracy: 0.9841\n","Epoch 20/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1479 - accuracy: 0.9891\n","Epoch 21/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1351 - accuracy: 0.9920\n","Epoch 22/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1343 - accuracy: 0.9861\n","Epoch 23/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1245 - accuracy: 0.9930\n","Epoch 24/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1154 - accuracy: 0.9930\n","Epoch 25/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1134 - accuracy: 0.9960\n","Epoch 26/100\n","32/32 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.9960\n","Epoch 27/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9970\n","Epoch 28/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9940\n","Epoch 29/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9960\n","Epoch 30/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9990\n","Epoch 31/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 0.9980\n","Epoch 32/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9960\n","Epoch 33/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9980\n","Epoch 34/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0835 - accuracy: 0.9980\n","Epoch 35/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9930\n","Epoch 36/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9980\n","Epoch 37/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.9940\n","Epoch 38/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0652 - accuracy: 0.9960\n","Epoch 39/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9980\n","Epoch 40/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0716 - accuracy: 0.9960\n","Epoch 41/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.9990\n","Epoch 42/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0573 - accuracy: 1.0000\n","Epoch 43/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0576 - accuracy: 0.9970\n","Epoch 44/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 1.0000\n","Epoch 45/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 1.0000\n","Epoch 46/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.9970\n","Epoch 47/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9990\n","Epoch 48/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9990\n","Epoch 49/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0415 - accuracy: 1.0000\n","Epoch 50/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9990\n","Epoch 51/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9990\n","Epoch 52/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9990\n","Epoch 53/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0401 - accuracy: 1.0000\n","Epoch 54/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0397 - accuracy: 0.9990\n","Epoch 55/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0383 - accuracy: 0.9990\n","Epoch 56/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9990\n","Epoch 57/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9990\n","Epoch 58/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 0.9990\n","Epoch 59/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 1.0000\n","Epoch 60/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 1.0000\n","Epoch 61/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9990\n","Epoch 62/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9980\n","Epoch 63/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 1.0000\n","Epoch 64/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9970\n","Epoch 65/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 0.9990\n","Epoch 66/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 1.0000\n","Epoch 67/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0266 - accuracy: 0.9990\n","Epoch 68/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 1.0000\n","Epoch 69/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0308 - accuracy: 0.9990\n","Epoch 70/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 1.0000\n","Epoch 71/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 1.0000\n","Epoch 72/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9990\n","Epoch 73/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 0.9980\n","Epoch 74/100\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 1.0000\n","Epoch 75/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 1.0000\n","Epoch 76/100\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9990\n","Epoch 77/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 1.0000\n","Epoch 78/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 1.0000\n","Epoch 79/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0211 - accuracy: 1.0000\n","Epoch 80/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 0.9970\n","Epoch 81/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0195 - accuracy: 1.0000\n","Epoch 82/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0205 - accuracy: 1.0000\n","Epoch 83/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0173 - accuracy: 1.0000\n","Epoch 84/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 1.0000\n","Epoch 85/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0213 - accuracy: 0.9990\n","Epoch 86/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0197 - accuracy: 0.9990\n","Epoch 87/100\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0196 - accuracy: 1.0000\n","Epoch 88/100\n","32/32 [==============================] - 0s 7ms/step - loss: 0.0196 - accuracy: 0.9990\n","Epoch 89/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 1.0000\n","Epoch 90/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 1.0000\n","Epoch 91/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 1.0000\n","Epoch 92/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 0.9980\n","Epoch 93/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 1.0000\n","Epoch 94/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 1.0000\n","Epoch 95/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 1.0000\n","Epoch 96/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 1.0000\n","Epoch 97/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 1.0000\n","Epoch 98/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9980\n","Epoch 99/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0140 - accuracy: 1.0000\n","Epoch 100/100\n","32/32 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 1.0000\n"]}]},{"cell_type":"code","source":["# 20 epochs\n","model.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRnaGyNKkTd0","executionInfo":{"status":"ok","timestamp":1651308210826,"user_tz":240,"elapsed":143,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"a6b8530a-f847-48a5-cf9c-cf43817be68d"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["14/14 [==============================] - 0s 3ms/step - loss: 3.4915 - accuracy: 0.4478\n"]},{"output_type":"execute_result","data":{"text/plain":["[3.4915149211883545, 0.4477958381175995]"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["ans = model.predict(test_dataset)"],"metadata":{"id":"BZKuFfl_lEhL","executionInfo":{"status":"ok","timestamp":1651308196567,"user_tz":240,"elapsed":136,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["ans[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJmCS0PJmQ91","executionInfo":{"status":"ok","timestamp":1651307566024,"user_tz":240,"elapsed":161,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"bdeb1a3e-cbec-46e4-be52-3bb84c9ca5d2"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20,)"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["y_test[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zM4g8D2m2xO","executionInfo":{"status":"ok","timestamp":1651307692344,"user_tz":240,"elapsed":157,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"a3b3a0bd-f559-4bdd-f427-5e22afa076a1"},"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0.], dtype=float32)"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["print(accuracy_score(y_test, np_utils.to_categorical(np.argmax(ans,axis=1))))\n","print(classification_report(y_test, np_utils.to_categorical(np.argmax(ans,axis=1))),)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5-fxTPKnEBc","executionInfo":{"status":"ok","timestamp":1651308199203,"user_tz":240,"elapsed":134,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"67bd4d7f-cb73-4ad1-c5d1-577cc3970941"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["0.44779582366589327\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.50      0.67         2\n","           1       0.00      0.00      0.00         7\n","           2       0.15      0.23      0.18        26\n","           3       0.29      0.15      0.20        13\n","           4       0.36      0.39      0.37        23\n","           5       0.00      0.00      0.00         2\n","           6       0.50      0.50      0.50        38\n","           7       0.45      0.54      0.49        41\n","           8       0.29      0.29      0.29         7\n","           9       1.00      0.50      0.67         4\n","          10       0.00      0.00      0.00         8\n","          11       0.61      0.64      0.62        84\n","          12       0.71      1.00      0.83        12\n","          13       0.43      0.52      0.47        44\n","          14       0.35      0.28      0.31        46\n","          15       0.39      0.35      0.37        40\n","          16       0.86      0.80      0.83        15\n","          17       0.00      0.00      0.00         3\n","          18       0.50      0.18      0.27        11\n","          19       0.00      0.00      0.00         5\n","\n","   micro avg       0.45      0.45      0.45       431\n","   macro avg       0.39      0.34      0.35       431\n","weighted avg       0.44      0.45      0.44       431\n"," samples avg       0.45      0.45      0.45       431\n","\n"]}]},{"cell_type":"code","source":["np_utils.to_categorical(np.argmax(ans[:2],axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dMu3KH2RlKgF","executionInfo":{"status":"ok","timestamp":1651307720266,"user_tz":240,"elapsed":131,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"58908537-2d02-450b-a66d-c4dd709ba99b"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n","        0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 1.]], dtype=float32)"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["# 10 epochs\n","model.evaluate(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_IzcSpDj7tU","executionInfo":{"status":"ok","timestamp":1651306908031,"user_tz":240,"elapsed":325,"user":{"displayName":"Keanu Nichols","userId":"11745476438285465974"}},"outputId":"ef2aa982-a488-45bc-8f34-66d1948110ac"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["14/14 [==============================] - 0s 3ms/step - loss: 1.8786 - accuracy: 0.4130\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.8785860538482666, 0.41299304366111755]"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["result = model.fit(values, Y_train[:400],\n","                    epochs=2, batch_size=32,\n","                    verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"BIBc1qFCo3Mo","executionInfo":{"status":"error","timestamp":1651303362829,"user_tz":240,"elapsed":313,"user":{"displayName":"Keanu Nichols","userId":"15455753636681602329"}},"outputId":"bd8e05b4-65cf-4067-f31b-96568681e7de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-5be2f91cad7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m result = model.fit(values, Y_train[:400],\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     verbose=1)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m   raise TypeError(f\"Cannot convert the argument `type_value`: {type_value!r} \"\n\u001b[0m\u001b[1;32m    722\u001b[0m                   \"to a TensorFlow DType.\")\n","\u001b[0;31mTypeError\u001b[0m: Cannot convert the argument `type_value`: torch.float32 to a TensorFlow DType."]}]},{"cell_type":"markdown","source":["https://austingwalters.com/classify-sentences-via-a-multilayer-perceptron-mlp/\n","https://github.com/holbertonschool/deep-learning/blob/master/Class%20%233/Text%20Classification%20MLP%20Reuters%20Dataset.ipynb\n","https://towardsdatascience.com/text-classification-with-extremely-small-datasets-333d322caee2\n","\n","\n","Hidden state (embeddings):\n","https://github.com/huggingface/transformers/issues/1950"],"metadata":{"id":"6fJxfhEyrzqu"}}],"metadata":{"colab":{"name":"MD5_1 (1).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}