{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xfFt0u5OQXrs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "from typing import List, Dict, Tuple, Callable, Iterable, Optional, Any\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numpy import save\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF3gDP8cRzCI",
        "outputId": "19c4e596-c257-4df2-d93c-d21b3f1510c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder_ = 'drive/MyDrive/Masters/Year_1/Semester_2/CS_505/Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYn8iNg-Q9f4",
        "outputId": "acffbeb3-4103-4152-9ebe-3113128d7252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 9.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 31.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 18.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (4.2.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.49)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=aaa16dec3aa781102f1d6ce0dac670767905338c6efeba79b8414da5fbb4e3b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.0 sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zLo6wg4XRBPV"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, models, InputExample, losses\n",
        "from sentence_transformers.evaluation import LabelAccuracyEvaluator, SentenceEvaluator\n",
        "from sentence_transformers.util import batch_to_device\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import MT5EncoderModel, AutoConfig,T5Tokenizer\n",
        "from transformers import pipeline, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ymk91t-DWStx"
      },
      "outputs": [],
      "source": [
        "train_df=pd.read_csv(folder_ + 'Data/Train.csv')\n",
        "train_df_english=pd.read_csv(folder_ + 'Data/train_google_translated.csv')\n",
        "\n",
        "#test_df=pd.read_csv('C:/Users/leose/second_semester/NLP/malawi_news_classification/data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a3w1gF-dWc_4"
      },
      "outputs": [],
      "source": [
        "train_df['Text']=train_df['Text'].tolist()\n",
        "train_df_english['Text']=train_df_english['Text'].tolist()\n",
        "#test_df['Text']=test_df['Text'].tolist()\n",
        "#test_batch_sentences=[]\n",
        "\n",
        "#for frame in train_df['Text']:\n",
        "#    train_batch_sentences.append(frame)\n",
        "#for sentence in test_df['Text']:\n",
        "#    test_batch_sentences.append(frame)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df))\n",
        "print(len(train_df_english))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2ka1QlWfkgH",
        "outputId": "d3551515-c917-428c-bbc1-9b9e4c751573"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1436\n",
            "1436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chichewa_embd = np.load(folder_ + 'Data/' + 'embeddings_chichewa_512_final.npy')"
      ],
      "metadata": {
        "id": "iqJWgCLOgT6n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_embd = np.load(folder_ + 'Data/' + 'embeddings_english_512_final.npy')"
      ],
      "metadata": {
        "id": "BGu-XATaIJL6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_comb_arr = np.hstack((chichewa_embd,english_embd))"
      ],
      "metadata": {
        "id": "f7vR0qPgJMlq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_comb_arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvRsJtP9JgRY",
        "outputId": "3db96a4c-e4f7-4330-fd27-77bdf542c669"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1436, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "train_df.Label = le.fit_transform(train_df.Label)"
      ],
      "metadata": {
        "id": "AghmKiVUoB7G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = np_utils.to_categorical(train_df['Label'], np.unique(train_df['Label']).shape[0])"
      ],
      "metadata": {
        "id": "zbxR9sxTnO8t"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train.shape)\n",
        "print(Y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiNySUtzoH-O",
        "outputId": "c047d653-bc99-49d2-8a79-cab99f4cefba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1436, 20)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Building model...')\n",
        "model = Sequential()\n",
        "model.add(Dense(2048, input_shape=(1024,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(Dense(1024, input_shape=(2048,)))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(20))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#make one, takes in, double that amount, english and chichewa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZhUUJbJoQ_x",
        "outputId": "3942f197-55ef-48ec-9e73-a10bd7084bdc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlXfKNP2oyPU",
        "outputId": "646c32f4-7596-4571-ba2d-537495fb84de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2048)              2099200   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                40980     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 20)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,140,180\n",
            "Trainable params: 2,140,180\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        final_comb_arr, Y_train, test_size=0.3, random_state=42, stratify=Y_train)"
      ],
      "metadata": {
        "id": "NLzLqYgEjM0y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebg0U5ORjccQ",
        "outputId": "a16cd01a-5693-46fd-b854-4ea29844fecc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1005, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB8KC9CvKdpr",
        "outputId": "41611505-cf51-4e85-e694-6066ae5290b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.02148693, -0.0798831 ,  0.02649599, ...,  0.17925473,\n",
              "       -0.07263725, -0.07171253], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nq94lFdYo9D",
        "outputId": "daf0a753-d8f5-44ed-d239-cb0fcdb784b8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8zM6igJjeF2",
        "outputId": "84b113f3-757b-4333-8b35-3dab5ac6aa57"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset = tf.data.Dataset.from_tensor_slices((values.detach().numpy(), Y_train[:400]))\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
      ],
      "metadata": {
        "id": "3y0MmA6cWxK2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gdvG8KAVZNuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "0BFtZ67-XLN6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.fit(train_dataset,\n",
        "                    epochs=50, batch_size=32,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "QZfSXN_PopGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2527c98-8ee9-4f5d-b6d4-bea967e93833"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 2ms/step - loss: 2.4366 - accuracy: 0.2736\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.9687 - accuracy: 0.4249\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.7691 - accuracy: 0.4697\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.6460 - accuracy: 0.5045\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.5000 - accuracy: 0.5423\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.4075 - accuracy: 0.5692\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.3735 - accuracy: 0.5990\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3179 - accuracy: 0.5871\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.2777 - accuracy: 0.5970\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.1719 - accuracy: 0.6358\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.1445 - accuracy: 0.6488\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.0948 - accuracy: 0.6716\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0669 - accuracy: 0.6736\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0226 - accuracy: 0.7015\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0120 - accuracy: 0.6786\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.9395 - accuracy: 0.7164\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.9240 - accuracy: 0.7274\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8713 - accuracy: 0.7383\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.7284\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8653 - accuracy: 0.7303\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8039 - accuracy: 0.7622\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8276 - accuracy: 0.7433\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7240 - accuracy: 0.7841\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.7761\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.7960\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.7950\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.7930\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.8090\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.7930\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.8159\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.8279\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.8408\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.8468\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8567\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8448\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.8398\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.8617\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.8667\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8826\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.8547\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8806\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8836\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8886\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8925\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.9055\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8995\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.9005\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.9164\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8995\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.9005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 50 epochs\n",
        "# New \n",
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "Rbrs3ku9opuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62177cdd-48c3-427f-dc74-f4d6ba12203d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 1.7091 - accuracy: 0.5476\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7091234922409058, 0.5475637912750244]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "TSvg8hplY9Pp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_test, np_utils.to_categorical(np.argmax(ans,axis=1))))\n",
        "print(classification_report(y_test, np_utils.to_categorical(np.argmax(ans,axis=1))),)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9QT0IQmY_yL",
        "outputId": "fd67e66b-6e97-4b7a-d090-71b74fc1d5e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5475638051044084\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       0.50      0.43      0.46         7\n",
            "           2       0.43      0.23      0.30        26\n",
            "           3       0.71      0.38      0.50        13\n",
            "           4       0.61      0.83      0.70        23\n",
            "           5       1.00      0.50      0.67         2\n",
            "           6       0.59      0.63      0.61        38\n",
            "           7       0.55      0.56      0.55        41\n",
            "           8       0.50      0.29      0.36         7\n",
            "           9       0.40      0.50      0.44         4\n",
            "          10       0.00      0.00      0.00         8\n",
            "          11       0.67      0.71      0.69        84\n",
            "          12       1.00      0.67      0.80        12\n",
            "          13       0.75      0.48      0.58        44\n",
            "          14       0.34      0.52      0.41        46\n",
            "          15       0.38      0.45      0.41        40\n",
            "          16       0.80      0.80      0.80        15\n",
            "          17       0.00      0.00      0.00         3\n",
            "          18       0.40      0.55      0.46        11\n",
            "          19       0.25      0.20      0.22         5\n",
            "\n",
            "   micro avg       0.55      0.55      0.55       431\n",
            "   macro avg       0.52      0.46      0.47       431\n",
            "weighted avg       0.56      0.55      0.54       431\n",
            " samples avg       0.55      0.55      0.55       431\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Building model...')\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(2048, input_shape=(1024,)))\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "#model.add(Dense(1024, input_shape=(2048,)))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model_2.add(Dense(20))\n",
        "model_2.add(Activation('softmax'))\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#make one, takes in, double that amount, english and chichewa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2rH5s6jZPUr",
        "outputId": "134f1406-9d66-4769-ddec-4f3b17eb1a2b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model_2.fit(train_dataset,\n",
        "                    epochs=100, batch_size=32,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJq_So_aW6X_",
        "outputId": "ec944f4e-174f-4af3-b2d1-9182759b84de"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4622 - accuracy: 0.2388\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 2.0347 - accuracy: 0.3781\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.7830 - accuracy: 0.4716\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.6455 - accuracy: 0.5045\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.5287 - accuracy: 0.5234\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.4257 - accuracy: 0.5552\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.3624 - accuracy: 0.5861\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.2813 - accuracy: 0.5960\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2652 - accuracy: 0.6030\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.2001 - accuracy: 0.6299\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.1515 - accuracy: 0.6438\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.0897 - accuracy: 0.6667\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.0741 - accuracy: 0.6716\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.0054 - accuracy: 0.6896\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 1.0336 - accuracy: 0.6846\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.9715 - accuracy: 0.6836\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.9119 - accuracy: 0.7254\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8964 - accuracy: 0.7284\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8589 - accuracy: 0.7393\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8219 - accuracy: 0.7622\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7938 - accuracy: 0.7692\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7808 - accuracy: 0.7582\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8012 - accuracy: 0.7672\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.7871\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.7891\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.7960\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.8169\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.7980\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.8169\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.8269\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.8209\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.8408\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.8209\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.8388\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8537\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8657\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8657\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8716\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8826\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8806\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8706\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8806\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8925\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8905\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.9005\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.9015\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.9134\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.9174\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8965\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.9075\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.9194\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.9224\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.9234\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.9294\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.9333\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.9303\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.9124\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9423\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9393\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9423\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9582\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9483\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9512\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9602\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9572\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.9652\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9602\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9731\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1521 - accuracy: 0.9682\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9692\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9642\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9761\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9622\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9692\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9711\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1357 - accuracy: 0.9731\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9831\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9801\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9821\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9831\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9771\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9851\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9851\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9761\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9751\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9801\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9682\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9662\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9552\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9781\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9801\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1051 - accuracy: 0.9821\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9881\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9871\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9930\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9871\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9930\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9871\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9950\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 100 epochs\n",
        "model_2.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRnaGyNKkTd0",
        "outputId": "fa75ea47-bdaa-4f1c-c300-b4fa297307a8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 2.3679 - accuracy: 0.5104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3679163455963135, 0.5104408264160156]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = model_2.predict(test_dataset)"
      ],
      "metadata": {
        "id": "BZKuFfl_lEhL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_test, np_utils.to_categorical(np.argmax(ans,axis=1))))\n",
        "print(classification_report(y_test, np_utils.to_categorical(np.argmax(ans,axis=1))),)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5-fxTPKnEBc",
        "outputId": "553fa711-7c3d-4ed1-c66b-8ac5e62e56f4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5104408352668214\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.50      0.40         2\n",
            "           1       0.50      0.14      0.22         7\n",
            "           2       0.40      0.15      0.22        26\n",
            "           3       0.57      0.31      0.40        13\n",
            "           4       0.67      0.78      0.72        23\n",
            "           5       1.00      0.50      0.67         2\n",
            "           6       0.68      0.50      0.58        38\n",
            "           7       0.43      0.63      0.51        41\n",
            "           8       0.50      0.29      0.36         7\n",
            "           9       0.40      0.50      0.44         4\n",
            "          10       0.00      0.00      0.00         8\n",
            "          11       0.72      0.62      0.67        84\n",
            "          12       1.00      0.50      0.67        12\n",
            "          13       0.57      0.55      0.56        44\n",
            "          14       0.31      0.52      0.39        46\n",
            "          15       0.36      0.45      0.40        40\n",
            "          16       0.80      0.80      0.80        15\n",
            "          17       0.00      0.00      0.00         3\n",
            "          18       0.45      0.45      0.45        11\n",
            "          19       0.17      0.20      0.18         5\n",
            "\n",
            "   micro avg       0.51      0.51      0.51       431\n",
            "   macro avg       0.49      0.42      0.43       431\n",
            "weighted avg       0.54      0.51      0.51       431\n",
            " samples avg       0.51      0.51      0.51       431\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Building model...')\n",
        "model_3 = Sequential()\n",
        "model_3.add(Dense(2048, input_shape=(1024,)))\n",
        "model_3.add(Activation('relu'))\n",
        "model_3.add(Dropout(0.2))\n",
        "#model.add(Dense(1024, input_shape=(2048,)))\n",
        "#model.add(Activation('relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model_3.add(Dense(20))\n",
        "model_3.add(Activation('softmax'))\n",
        "\n",
        "model_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#make one, takes in, double that amount, english and chichewa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpS8tKIKaFcI",
        "outputId": "371ba230-c0a3-4a2d-a581-d977ceb34c04"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model_3.fit(train_dataset,\n",
        "                    epochs=100, batch_size=64,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHPqFo9oaMM3",
        "outputId": "a7693dec-eb86-4281-a397-40ecfb72a376"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.4179 - accuracy: 0.2607\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.9981 - accuracy: 0.4259\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.7569 - accuracy: 0.4896\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.6342 - accuracy: 0.5114\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.5268 - accuracy: 0.5224\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4447 - accuracy: 0.5672\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3496 - accuracy: 0.5821\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3001 - accuracy: 0.5980\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2478 - accuracy: 0.6169\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.2086 - accuracy: 0.6189\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1699 - accuracy: 0.6378\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0958 - accuracy: 0.6547\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0553 - accuracy: 0.6776\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0319 - accuracy: 0.6796\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.0031 - accuracy: 0.7005\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.9725 - accuracy: 0.6965\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.9291 - accuracy: 0.7134\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.7184\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.7373\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8280 - accuracy: 0.7582\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.8181 - accuracy: 0.7483\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7830 - accuracy: 0.7741\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7633 - accuracy: 0.7692\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7172 - accuracy: 0.7891\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.7811\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.8109\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.8229\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.8239\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.8428\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.8169\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.8438\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.8517\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.8428\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.8478\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.8418\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.8289\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8537\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8627\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8736\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8627\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8886\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.9015\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8896\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.9025\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.9085\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.9095\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.9204\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.9075\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.9025\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.9164\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.9274\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.9234\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2631 - accuracy: 0.9383\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9423\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9433\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9343\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2291 - accuracy: 0.9413\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9234\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9542\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9483\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9522\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9383\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9632\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9562\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9741\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9721\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9542\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9721\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9731\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9821\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9731\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9751\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9672\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9622\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9721\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9711\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9821\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9900\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9801\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1043 - accuracy: 0.9801\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9771\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9851\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9881\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9881\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9841\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9910\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0809 - accuracy: 0.9900\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0899 - accuracy: 0.9861\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9900\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9881\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9851\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9910\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9910\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9940\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9950\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9920\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9881\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9920\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNMbF5J_aVX4",
        "outputId": "1c60b81e-c0e6-471e-c623-d847a4c4690e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 2.3081 - accuracy: 0.5197\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.308051347732544, 0.5197215676307678]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://austingwalters.com/classify-sentences-via-a-multilayer-perceptron-mlp/\n",
        "https://github.com/holbertonschool/deep-learning/blob/master/Class%20%233/Text%20Classification%20MLP%20Reuters%20Dataset.ipynb\n",
        "https://towardsdatascience.com/text-classification-with-extremely-small-datasets-333d322caee2\n",
        "\n",
        "\n",
        "Hidden state (embeddings):\n",
        "https://github.com/huggingface/transformers/issues/1950"
      ],
      "metadata": {
        "id": "6fJxfhEyrzqu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "MT5_final_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}