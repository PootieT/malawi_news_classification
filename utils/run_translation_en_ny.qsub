#!/bin/bash -l

# Set SCC project
#$ -P cs505

# Specify hard time limit for the job. 
#   The job will be aborted if it runs longer than this time.
#   The default time is 12 hours
#$ -l h_rt=12:00:00

# Send an email when the job finishes or if it is aborted (by default no email is sent).
######$ -m ea

# Give job a name
#$ -N translate

# Combine output and error files into a single file
#$ -j y

# request 6 cores, each with 6 GB RAM at least
#$ -pe omp 3
###$ -l mem_per_core=6G

# request 1 GPU
#$ -l gpus=1
#$ -l gpu_c=6.0
#$ -l gpu_type=V100

# Submit an array job with 5 tasks 
#$ -t 6-20

DATA_SPLITS=(`ls ../realnews/realnews.jsonl*`)

index=$(($SGE_TASK_ID-1))
DATA=${DATA_SPLITS[$index]}
filename="${DATA##*/}"
fidx="${filename:14 }"
OUT="../realnews/realnews_ny.jsonl${fidx}"

echo "=========================================================="
echo "Start date : $(date)"
echo "Job name : $JOB_NAME"
echo "Job ID : $JOB_ID  $SGE_TASK_ID"
echo "=========================================================="
nvidia-smi
echo "in file: ${DATA}, outfile: ${OUT}"

module load anaconda3/5.2.0
source activate /projectnb2/llamagrp/peter/ContrastiveAugmentation/envs
export TRANSFORMERS_CACHE=/projectnb2/cs505/projects/contrastive/huggingface_cache/
export HF_DATASETS_CACHE="/projectnb2/cs505/projects/contrastive/huggingface_cache/"
export WANDB_CONFIG_DIR="/project/llamagrp/peter"
python malawi_news_classification/utils/translate_to_english.py\
	-in_file $DATA -out_file $OUT -batch_size 64
mv $DATA "../realnews/realnews_en.jsonl${fidx}"
