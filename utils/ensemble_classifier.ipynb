{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projectnb2/cs505/students/lseoane/malawi_news_classification/utils'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_arr1 = np.load(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/'+'eng_and_chich_split_texts' '.npy')\n",
    "# final_arr2 = np.load(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/'+'embeddings_chichewa' '.npy')\n",
    "# print(final_arr1.shape)\n",
    "# print(final_arr2.shape)\n",
    "# final_arr=np.hstack([final_arr1,final_arr2])\n",
    "final_arr=final_arr1\n",
    "\n",
    "labels=pd.read_csv(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/'+'eng_and_chich_split_labels'+'.csv')\n",
    "target_names=labels['Label'].unique().astype(str).tolist()\n",
    "labels=labels['Label'].values\n",
    "\n",
    "idx=pd.read_csv(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/'+'eng_and_chich_split_index'+'.csv')\n",
    "idx=idx['Idx'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POLITICS', 'HEALTH', 'LAW/ORDER', 'RELIGION', 'FARMING', 'WILDLIFE/ENVIRONMENT', 'SOCIAL ISSUES', 'SOCIAL', 'OPINION/ESSAY', 'LOCALCHIEFS', 'WITCHCRAFT', 'ECONOMY', 'SPORTS', 'RELATIONSHIPS', 'TRANSPORT', 'CULTURE', 'EDUCATION', 'MUSIC', 'ARTS AND CRAFTS', 'FLOODING']\n"
     ]
    }
   ],
   "source": [
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(target_names)\n",
    "\n",
    "f_target_names=le.transform(target_names)\n",
    "labels=le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n"
     ]
    }
   ],
   "source": [
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  6  7 13  4 18 15 14 10  8 19  2 16 12 17  1  3  9  0  5]\n"
     ]
    }
   ],
   "source": [
    "print(f_target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_target_names=f_target_names.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8541"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 0.4179838426413769\n",
      "xgb               precision    recall  f1-score   support\n",
      "\n",
      "          11       0.57      0.24      0.33        17\n",
      "           6       0.18      0.04      0.06        77\n",
      "           7       0.21      0.21      0.21       188\n",
      "          13       0.39      0.25      0.30        68\n",
      "           4       0.51      0.45      0.47       191\n",
      "          18       0.00      0.00      0.00        15\n",
      "          15       0.42      0.28      0.34       193\n",
      "          14       0.35      0.30      0.32       248\n",
      "          10       0.56      0.13      0.21        70\n",
      "           8       0.27      0.13      0.18        46\n",
      "          19       0.00      0.00      0.00        74\n",
      "           2       0.44      0.73      0.55       600\n",
      "          16       0.64      0.69      0.66       152\n",
      "          12       0.55      0.50      0.52       170\n",
      "          17       0.30      0.25      0.27       134\n",
      "           1       0.35      0.47      0.40       375\n",
      "           3       0.77      0.51      0.62       109\n",
      "           9       0.00      0.00      0.00        18\n",
      "           0       0.12      0.03      0.05        59\n",
      "           5       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.42      2847\n",
      "   macro avg       0.33      0.26      0.28      2847\n",
      "weighted avg       0.39      0.42      0.39      2847\n",
      "\n",
      "lgr 0.44186863364945556\n",
      "lgr               precision    recall  f1-score   support\n",
      "\n",
      "          11       0.00      0.00      0.00        17\n",
      "           6       0.06      0.01      0.02        77\n",
      "           7       0.28      0.29      0.28       188\n",
      "          13       0.39      0.32      0.35        68\n",
      "           4       0.52      0.50      0.51       191\n",
      "          18       0.00      0.00      0.00        15\n",
      "          15       0.48      0.33      0.39       193\n",
      "          14       0.43      0.37      0.40       248\n",
      "          10       0.42      0.07      0.12        70\n",
      "           8       0.42      0.17      0.25        46\n",
      "          19       0.00      0.00      0.00        74\n",
      "           2       0.45      0.77      0.57       600\n",
      "          16       0.65      0.78      0.71       152\n",
      "          12       0.46      0.49      0.47       170\n",
      "          17       0.29      0.21      0.24       134\n",
      "           1       0.36      0.42      0.39       375\n",
      "           3       0.80      0.60      0.68       109\n",
      "           9       0.00      0.00      0.00        18\n",
      "           0       0.33      0.02      0.03        59\n",
      "           5       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.44      2847\n",
      "   macro avg       0.32      0.27      0.27      2847\n",
      "weighted avg       0.41      0.44      0.41      2847\n",
      "\n",
      "RF 0.4137688795223042\n",
      "RF               precision    recall  f1-score   support\n",
      "\n",
      "          11       1.00      0.29      0.45        17\n",
      "           6       0.08      0.01      0.02        77\n",
      "           7       0.28      0.15      0.20       188\n",
      "          13       0.56      0.13      0.21        68\n",
      "           4       0.48      0.48      0.48       191\n",
      "          18       0.00      0.00      0.00        15\n",
      "          15       0.43      0.22      0.29       193\n",
      "          14       0.37      0.27      0.32       248\n",
      "          10       0.00      0.00      0.00        70\n",
      "           8       0.10      0.02      0.04        46\n",
      "          19       0.00      0.00      0.00        74\n",
      "           2       0.40      0.80      0.53       600\n",
      "          16       0.61      0.74      0.67       152\n",
      "          12       0.50      0.46      0.48       170\n",
      "          17       0.27      0.13      0.17       134\n",
      "           1       0.34      0.50      0.40       375\n",
      "           3       0.82      0.51      0.63       109\n",
      "           9       0.00      0.00      0.00        18\n",
      "           0       1.00      0.02      0.03        59\n",
      "           5       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.41      2847\n",
      "   macro avg       0.36      0.24      0.25      2847\n",
      "weighted avg       0.39      0.41      0.36      2847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 0.42992623814541625\n",
      "xgb               precision    recall  f1-score   support\n",
      "\n",
      "          11       0.00      0.00      0.00        17\n",
      "           6       0.38      0.10      0.16        78\n",
      "           7       0.23      0.16      0.19       187\n",
      "          13       0.57      0.19      0.29        68\n",
      "           4       0.53      0.48      0.51       190\n",
      "          18       0.00      0.00      0.00        16\n",
      "          15       0.39      0.31      0.34       194\n",
      "          14       0.35      0.29      0.31       248\n",
      "          10       0.29      0.08      0.13        71\n",
      "           8       0.43      0.20      0.27        45\n",
      "          19       0.00      0.00      0.00        73\n",
      "           2       0.45      0.75      0.56       599\n",
      "          16       0.71      0.72      0.71       152\n",
      "          12       0.53      0.45      0.49       170\n",
      "          17       0.33      0.24      0.28       135\n",
      "           1       0.32      0.49      0.39       374\n",
      "           3       0.79      0.75      0.77       110\n",
      "           9       1.00      0.06      0.11        17\n",
      "           0       0.17      0.03      0.06        60\n",
      "           5       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.43      2847\n",
      "   macro avg       0.37      0.27      0.28      2847\n",
      "weighted avg       0.41      0.43      0.40      2847\n",
      "\n",
      "lgr 0.4495960660344222\n",
      "lgr               precision    recall  f1-score   support\n",
      "\n",
      "          11       0.00      0.00      0.00        17\n",
      "           6       0.46      0.08      0.13        78\n",
      "           7       0.24      0.18      0.21       187\n",
      "          13       0.58      0.26      0.36        68\n",
      "           4       0.52      0.56      0.54       190\n",
      "          18       0.00      0.00      0.00        16\n",
      "          15       0.40      0.35      0.37       194\n",
      "          14       0.46      0.36      0.40       248\n",
      "          10       0.22      0.06      0.09        71\n",
      "           8       0.39      0.31      0.35        45\n",
      "          19       0.00      0.00      0.00        73\n",
      "           2       0.46      0.77      0.58       599\n",
      "          16       0.67      0.76      0.71       152\n",
      "          12       0.50      0.48      0.49       170\n",
      "          17       0.38      0.23      0.29       135\n",
      "           1       0.33      0.44      0.38       374\n",
      "           3       0.75      0.77      0.76       110\n",
      "           9       0.00      0.00      0.00        17\n",
      "           0       0.00      0.00      0.00        60\n",
      "           5       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.45      2847\n",
      "   macro avg       0.32      0.28      0.28      2847\n",
      "weighted avg       0.41      0.45      0.41      2847\n",
      "\n",
      "RF 0.42957499121882686\n",
      "RF               precision    recall  f1-score   support\n",
      "\n",
      "          11       0.00      0.00      0.00        17\n",
      "           6       1.00      0.03      0.05        78\n",
      "           7       0.22      0.12      0.15       187\n",
      "          13       0.80      0.12      0.21        68\n",
      "           4       0.51      0.48      0.49       190\n",
      "          18       0.00      0.00      0.00        16\n",
      "          15       0.38      0.24      0.29       194\n",
      "          14       0.40      0.29      0.33       248\n",
      "          10       0.00      0.00      0.00        71\n",
      "           8       0.40      0.04      0.08        45\n",
      "          19       0.00      0.00      0.00        73\n",
      "           2       0.43      0.82      0.56       599\n",
      "          16       0.69      0.74      0.71       152\n",
      "          12       0.58      0.49      0.53       170\n",
      "          17       0.43      0.15      0.22       135\n",
      "           1       0.30      0.53      0.39       374\n",
      "           3       0.80      0.68      0.74       110\n",
      "           9       1.00      0.12      0.21        17\n",
      "           0       0.00      0.00      0.00        60\n",
      "           5       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.43      2847\n",
      "   macro avg       0.40      0.24      0.25      2847\n",
      "weighted avg       0.42      0.43      0.38      2847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 0.42887249736564803\n",
      "xgb               precision    recall  f1-score   support\n",
      "\n",
      "          11       1.00      0.35      0.52        17\n",
      "           6       0.32      0.16      0.21        77\n",
      "           7       0.20      0.13      0.16       188\n",
      "          13       0.50      0.13      0.21        69\n",
      "           4       0.50      0.62      0.56       190\n",
      "          18       0.00      0.00      0.00        16\n",
      "          15       0.43      0.30      0.35       194\n",
      "          14       0.42      0.38      0.40       247\n",
      "          10       0.35      0.09      0.14        70\n",
      "           8       0.00      0.00      0.00        45\n",
      "          19       0.00      0.00      0.00        73\n",
      "           2       0.44      0.77      0.56       599\n",
      "          16       0.62      0.65      0.64       152\n",
      "          12       0.47      0.32      0.38       171\n",
      "          17       0.44      0.19      0.27       135\n",
      "           1       0.33      0.48      0.39       375\n",
      "           3       0.77      0.63      0.69       110\n",
      "           9       0.50      0.12      0.19        17\n",
      "           0       0.00      0.00      0.00        59\n",
      "           5       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.43      2847\n",
      "   macro avg       0.37      0.27      0.28      2847\n",
      "weighted avg       0.40      0.43      0.39      2847\n",
      "\n",
      "lgr 0.44608359676852827\n",
      "lgr               precision    recall  f1-score   support\n",
      "\n",
      "          11       0.00      0.00      0.00        17\n",
      "           6       0.31      0.06      0.11        77\n",
      "           7       0.24      0.15      0.18       188\n",
      "          13       0.48      0.19      0.27        69\n",
      "           4       0.47      0.62      0.53       190\n",
      "          18       0.00      0.00      0.00        16\n",
      "          15       0.46      0.37      0.41       194\n",
      "          14       0.45      0.41      0.43       247\n",
      "          10       0.39      0.10      0.16        70\n",
      "           8       0.22      0.04      0.07        45\n",
      "          19       0.00      0.00      0.00        73\n",
      "           2       0.45      0.80      0.57       599\n",
      "          16       0.61      0.74      0.66       152\n",
      "          12       0.51      0.40      0.45       171\n",
      "          17       0.49      0.16      0.24       135\n",
      "           1       0.35      0.47      0.41       375\n",
      "           3       0.72      0.62      0.66       110\n",
      "           9       0.00      0.00      0.00        17\n",
      "           0       0.00      0.00      0.00        59\n",
      "           5       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.45      2847\n",
      "   macro avg       0.31      0.26      0.26      2847\n",
      "weighted avg       0.41      0.45      0.40      2847\n",
      "\n",
      "RF 0.42079381805409205\n",
      "RF               precision    recall  f1-score   support\n",
      "\n",
      "          11       1.00      0.24      0.38        17\n",
      "           6       0.00      0.00      0.00        77\n",
      "           7       0.22      0.11      0.15       188\n",
      "          13       0.29      0.03      0.05        69\n",
      "           4       0.51      0.61      0.56       190\n",
      "          18       0.00      0.00      0.00        16\n",
      "          15       0.44      0.23      0.30       194\n",
      "          14       0.45      0.35      0.40       247\n",
      "          10       0.00      0.00      0.00        70\n",
      "           8       0.00      0.00      0.00        45\n",
      "          19       0.00      0.00      0.00        73\n",
      "           2       0.41      0.83      0.55       599\n",
      "          16       0.60      0.67      0.63       152\n",
      "          12       0.47      0.33      0.38       171\n",
      "          17       0.48      0.08      0.14       135\n",
      "           1       0.31      0.51      0.39       375\n",
      "           3       0.79      0.55      0.65       110\n",
      "           9       1.00      0.12      0.21        17\n",
      "           0       1.00      0.02      0.03        59\n",
      "           5       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.42      2847\n",
      "   macro avg       0.40      0.23      0.24      2847\n",
      "weighted avg       0.40      0.42      0.36      2847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier() \n",
    "lgr_model= LogisticRegression(random_state=np.random.seed(42))\n",
    "rand_forest = RandomForestClassifier(random_state=np.random.seed(42))\n",
    "\n",
    "X=final_arr\n",
    "y=labels\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf.get_n_splits(X,y)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    lgr_model=lgr_model.fit(X_train, y_train)\n",
    "    rand_forest.fit(X_train, y_train)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred = xgb_model.predict(X_test) \n",
    "    predictions = [value for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test,predictions) \n",
    "    print('xgb',accuracy)\n",
    "    clf_r=classification_report(y_test,predictions,target_names=f_target_names)\n",
    "    print('xgb',clf_r)\n",
    "#     cm=multilabel_confusion_matrix(y_test,predictions)\n",
    "#     print('xgb',cm)\n",
    "    \n",
    "    \n",
    "    y_pred = lgr_model.predict(X_test) \n",
    "    predictions = [value for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions) \n",
    "    print('lgr',accuracy)\n",
    "    clf_r=classification_report(y_test,predictions,target_names=f_target_names)\n",
    "    print('lgr',clf_r)\n",
    "#     cm=multilabel_confusion_matrix(y_test,predictions)\n",
    "#     print('lgr',cm)\n",
    "\n",
    "    y_pred = rand_forest.predict(X_test) \n",
    "    predictions = [value for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions) \n",
    "    print('RF',accuracy)\n",
    "    clf_r=classification_report(y_test,predictions,target_names=f_target_names)\n",
    "    print('RF',clf_r)\n",
    "#     cm=multilabel_confusion_matrix(y_test,predictions)\n",
    "#     print('RF',cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for i in range(0,len(final_arr)):\n",
    "    y_pred.append(lgr_model.predict([final_arr[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=pd.DataFrame(y_pred,columns=['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  3, 11,  9,  4,  6, 13,  7,  2, 18, 14, 16, 12,  8,  1, 10])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds['preds'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "final_df=pd.DataFrame(columns=['Preds','Labels','Indexes'])\n",
    "final_df['Preds']=y_preds['preds'].values\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(f_target_names)\n",
    "\n",
    "f_target_names=le.transform(f_target_names)\n",
    "labels=le.transform(labels)\n",
    "preds=le.transform(y_preds['preds'])\n",
    "final_df['Labels']=labels\n",
    "final_df['Preds']=preds\n",
    "final_df['Indexes']=idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=final_df.groupby('Indexes')['Preds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexes  Preds\n",
       "0        3         3\n",
       "         7         2\n",
       "         19        2\n",
       "         13        1\n",
       "         14        1\n",
       "                  ..\n",
       "1434     7         3\n",
       "         8         2\n",
       "         19        2\n",
       "         4         1\n",
       "1435     3        11\n",
       "Name: Preds, Length: 3340, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_labels=final_df.groupby('Indexes')['Labels'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indexes</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1431</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1432</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1433</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1434</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1435</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1436 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Indexes  Labels\n",
       "0           0       3\n",
       "1           1       3\n",
       "2           2      16\n",
       "3           3       3\n",
       "4           4      17\n",
       "...       ...     ...\n",
       "1431     1431       9\n",
       "1432     1432       3\n",
       "1433     1433      13\n",
       "1434     1434       7\n",
       "1435     1435       3\n",
       "\n",
       "[1436 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds=[]\n",
    "for i in range(0,1435):\n",
    "    final_preds.append(a[i].idxmax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3, 16, ..., 13,  7,  3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_labels['Labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5167130919220055\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(fin_labels['Labels'],final_preds) \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=classification_report(fin_labels['Labels'],final_preds,target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            POLITICS       0.00      0.00      0.00         7\n",
      "              HEALTH       0.00      0.00      0.00        23\n",
      "           LAW/ORDER       0.00      0.00      0.00        26\n",
      "            RELIGION       0.41      0.91      0.57       279\n",
      "             FARMING       0.83      0.97      0.89        39\n",
      "WILDLIFE/ENVIRONMENT       0.59      0.67      0.63       147\n",
      "       SOCIAL ISSUES       0.52      0.16      0.24       152\n",
      "              SOCIAL       0.46      0.59      0.52       134\n",
      "       OPINION/ESSAY       0.91      0.82      0.86        49\n",
      "         LOCALCHIEFS       0.00      0.00      0.00        11\n",
      "          WITCHCRAFT       1.00      0.03      0.05        36\n",
      "             ECONOMY       0.00      0.00      0.00        16\n",
      "              SPORTS       0.47      0.27      0.34        86\n",
      "       RELATIONSHIPS       0.65      0.30      0.41        43\n",
      "           TRANSPORT       0.65      0.68      0.67        78\n",
      "             CULTURE       0.00      0.00      0.00         7\n",
      "           EDUCATION       0.68      0.39      0.50       127\n",
      "               MUSIC       0.56      0.46      0.50       136\n",
      "     ARTS AND CRAFTS       0.00      0.00      0.00        25\n",
      "            FLOODING       0.70      0.47      0.56        15\n",
      "\n",
      "            accuracy                           0.52      1436\n",
      "           macro avg       0.42      0.34      0.34      1436\n",
      "        weighted avg       0.52      0.52      0.47      1436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
