{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,multilabel_confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embeddings\n",
    "# final_arr1 = np.load(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/'+'eng_and_chich_split_text_embeddings' '.npy')\n",
    "# final_arr2 = np.load(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/'+'eng_and_chich_split_translated_text' '.npy')\n",
    "# print(final_arr1.shape)\n",
    "# print(final_arr2.shape)\n",
    "# final_arr=np.hstack([final_arr1,final_arr2])\n",
    "# final_arr=final_arr1\n",
    "final_arr=np.load(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/final_embeddings''.npy')\n",
    "labels=pd.read_csv(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/'+'final_labels'+'.csv')\n",
    "target_names=labels['0'].unique().astype(str).tolist()\n",
    "labels=labels['0'].values\n",
    "\n",
    "# idx=pd.read_csv(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/'+'eng_and_chich_split_index'+'.csv')\n",
    "# idx=idx['Idx'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some embeddings need label encoding.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(target_names)\n",
    "\n",
    "f_target_names=le.transform(target_names)\n",
    "labels=le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_target_names=f_target_names.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgr 0.6369871327992231\n",
      "lgr               precision    recall  f1-score   support\n",
      "\n",
      "          11       0.97      0.94      0.96       889\n",
      "           6       0.55      0.45      0.49      1181\n",
      "           7       0.80      0.25      0.39       695\n",
      "          13       0.82      0.46      0.59       681\n",
      "           4       0.43      0.23      0.30       693\n",
      "          18       0.87      0.91      0.89       889\n",
      "          15       0.26      0.25      0.26       709\n",
      "          14       0.36      0.08      0.13       712\n",
      "          10       0.79      0.97      0.87      1284\n",
      "           8       0.80      0.84      0.82       965\n",
      "          19       0.45      0.83      0.59      1325\n",
      "           2       0.13      0.17      0.15        93\n",
      "          16       0.35      0.97      0.52       680\n",
      "          12       0.75      0.56      0.64       716\n",
      "          17       0.37      0.03      0.06       717\n",
      "           1       0.53      0.56      0.54       712\n",
      "           3       0.94      0.59      0.72       683\n",
      "           9       0.89      0.72      0.80       762\n",
      "           0       0.69      0.85      0.76      1146\n",
      "           5       0.77      0.91      0.84       944\n",
      "\n",
      "    accuracy                           0.64     16476\n",
      "   macro avg       0.63      0.58      0.57     16476\n",
      "weighted avg       0.66      0.64      0.61     16476\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgr 0.788965768390386\n",
      "lgr               precision    recall  f1-score   support\n",
      "\n",
      "          11       0.92      0.98      0.95       889\n",
      "           6       0.79      0.88      0.84      1181\n",
      "           7       0.54      0.23      0.32       696\n",
      "          13       0.71      0.67      0.69       681\n",
      "           4       0.54      0.64      0.58       692\n",
      "          18       0.95      1.00      0.97       889\n",
      "          15       0.63      0.47      0.53       709\n",
      "          14       0.90      0.76      0.82       712\n",
      "          10       0.77      0.94      0.85      1283\n",
      "           8       1.00      1.00      1.00       965\n",
      "          19       0.64      0.81      0.71      1325\n",
      "           2       0.25      0.10      0.14        93\n",
      "          16       0.99      0.93      0.96       679\n",
      "          12       0.69      0.77      0.73       716\n",
      "          17       0.64      0.61      0.62       718\n",
      "           1       0.92      0.63      0.75       711\n",
      "           3       0.78      0.74      0.76       683\n",
      "           9       0.99      1.00      1.00       763\n",
      "           0       0.72      0.65      0.68      1147\n",
      "           5       0.87      0.99      0.93       944\n",
      "\n",
      "    accuracy                           0.79     16476\n",
      "   macro avg       0.76      0.74      0.74     16476\n",
      "weighted avg       0.79      0.79      0.78     16476\n",
      "\n",
      "lgr 0.7262518968133536\n",
      "lgr               precision    recall  f1-score   support\n",
      "\n",
      "          11       0.91      1.00      0.95       889\n",
      "           6       0.81      0.76      0.78      1180\n",
      "           7       0.49      0.09      0.16       695\n",
      "          13       0.95      0.53      0.68       681\n",
      "           4       0.61      0.47      0.53       693\n",
      "          18       0.89      0.99      0.94       889\n",
      "          15       0.12      0.08      0.10       709\n",
      "          14       0.51      0.46      0.49       712\n",
      "          10       0.79      0.99      0.88      1283\n",
      "           8       0.91      1.00      0.95       965\n",
      "          19       0.60      0.82      0.69      1326\n",
      "           2       0.57      0.17      0.26        93\n",
      "          16       1.00      0.97      0.98       680\n",
      "          12       0.40      0.62      0.49       715\n",
      "          17       0.30      0.17      0.22       717\n",
      "           1       0.62      0.44      0.52       711\n",
      "           3       0.83      0.89      0.86       683\n",
      "           9       0.86      1.00      0.92       763\n",
      "           0       0.86      0.84      0.85      1147\n",
      "           5       0.75      1.00      0.86       944\n",
      "\n",
      "    accuracy                           0.73     16475\n",
      "   macro avg       0.69      0.67      0.66     16475\n",
      "weighted avg       0.71      0.73      0.70     16475\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# xgb_model = XGBClassifier() \n",
    "lgr_model= LogisticRegression(random_state=np.random.seed(42))\n",
    "# rand_forest = RandomForestClassifier(random_state=np.random.seed(42))\n",
    "\n",
    "X=final_arr\n",
    "y=labels\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf.get_n_splits(X,y)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    lgr_model=lgr_model.fit(X_train, y_train)\n",
    "#     rand_forest.fit(X_train, y_train)\n",
    "#     xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "#     y_pred = xgb_model.predict(X_test) \n",
    "#     predictions = [value for value in y_pred]\n",
    "#     accuracy = accuracy_score(y_test,predictions) \n",
    "#     print('xgb',accuracy)\n",
    "#     clf_r=classification_report(y_test,predictions,target_names=f_target_names)\n",
    "#     print('xgb',clf_r)\n",
    "# #     cm=multilabel_confusion_matrix(y_test,predictions)\n",
    "# #     print('xgb',cm)\n",
    "    \n",
    "    \n",
    "    y_pred = lgr_model.predict(X_test) \n",
    "    predictions = [value for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions) \n",
    "    print('lgr',accuracy)\n",
    "    clf_r=classification_report(y_test,predictions,target_names=f_target_names)\n",
    "    print('lgr',clf_r)\n",
    "#     cm=multilabel_confusion_matrix(y_test,predictions)\n",
    "#     print('lgr',cm)\n",
    "\n",
    "#     y_pred = rand_forest.predict(X_test) \n",
    "#     predictions = [value for value in y_pred]\n",
    "#     accuracy = accuracy_score(y_test, predictions) \n",
    "#     print('RF',accuracy)\n",
    "#     clf_r=classification_report(y_test,predictions,target_names=f_target_names)\n",
    "#     print('RF',clf_r)\n",
    "# #     cm=multilabel_confusion_matrix(y_test,predictions)\n",
    "# #     print('RF',cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions\n",
    "y_pred=[]\n",
    "for i in range(0,len(final_arr)):\n",
    "    y_pred.append(lgr_model.predict([final_arr[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=pd.DataFrame(y_pred,columns=['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#perform label encoding if necessary and get final df\n",
    "final_df=pd.DataFrame(columns=['Preds','Labels','Indexes'])\n",
    "final_df['Preds']=y_preds['preds'].values\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(f_target_names)\n",
    "\n",
    "f_target_names=le.transform(f_target_names)\n",
    "labels=le.transform(labels)\n",
    "\n",
    "preds=le.transform(y_preds['preds'])\n",
    "final_df['Labels']=labels\n",
    "final_df['Preds']=preds\n",
    "# final_df['Indexes']=idx.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 0 but corresponding boolean dimension is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-f97fcbe04086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ensemble predictions belonging to the same index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Indexes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Preds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[0;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# multi-index components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstructed_codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_codes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlevel_codes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mllab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_index\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mping\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selection_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(lab, inc)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mllab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 0 but corresponding boolean dimension is 1"
     ]
    }
   ],
   "source": [
    "#ensemble predictions belonging to the same index\n",
    "a=final_df.groupby('Indexes')['Preds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_labels=final_df.groupby('Indexes')['Labels'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds=[]\n",
    "for i in range(0,1435):\n",
    "    final_preds.append(a[i].idxmax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1436, 3295]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-8d6f39c9bc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1436, 3295]"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(fin_labels['Labels'],final_preds) \n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=classification_report(fin_labels['Labels'],final_preds,target_names=target_names)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_arr1 = np.load(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/data/'+'FINAL_eng'+'.npy')\n",
    "test_arr2 = np.load(f'/projectnb2/cs505/students/lseoane/malawi_news_classification/data/'+'FINAL_test_chich'+'.npy')\n",
    "test_index=pd.read_csv('/projectnb2/cs505/students/lseoane/malawi_news_classification/data/test_chich_splits_index.csv')\n",
    "final_test_arr=test_arr2\n",
    "# final_test_arr=np.hstack([test_arr1,test_arr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3632\n"
     ]
    }
   ],
   "source": [
    "print(len(test_arr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3632\n"
     ]
    }
   ],
   "source": [
    "print(len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for i in range(0,len(final_test_arr)):\n",
    "    y_pred.append(lgr_model.predict([final_test_arr[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_y_preds=[]\n",
    "for pred in y_pred:\n",
    "    a=pred[0]\n",
    "    alt_y_preds.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#perform label encoding if necessary and get final test df\n",
    "final_test_df=pd.DataFrame(columns=['Preds','Indexes'])\n",
    "final_test_df['Preds']=alt_y_preds\n",
    "\n",
    "final_test_df['Indexes']=test_index['Idx'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=final_test_df.groupby('Indexes')['Preds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes  Preds\n",
      "0        10       3\n",
      "         5        2\n",
      "         8        1\n",
      "1        1        1\n",
      "         7        1\n",
      "                 ..\n",
      "618      9        1\n",
      "         12       1\n",
      "619      8        6\n",
      "         10       2\n",
      "         16       1\n",
      "Name: Preds, Length: 1940, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_preds=[]\n",
    "for i in range(0,619):\n",
    "    final_preds.append(b[i].idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict={'0':'POLITICS','1':'HEALTH', '2':'LAW/ORDER', '3':'RELIGION', '4':'FARMING',\n",
    "       '5':'WILDLIFE/ENVIRONMENT', '6':'SOCIAL ISSUES', '7':'SOCIAL', '8':'OPINION/ESSAY',\n",
    "       '9':'LOCALCHIEFS', '10':'WITCHCRAFT', '11':'ECONOMY', '12':'SPORTS', '13':'RELATIONSHIPS',\n",
    "       '14':'TRANSPORT', '15':'CULTURE', '16':'EDUCATION', '17':'MUSIC', '18':'ARTS AND CRAFTS',\n",
    "       '19':'FLOODING'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_preds=[]\n",
    "for value in b:\n",
    "    final_test_preds.append(label_dict[str(value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/projectnb2/cs505/students/lseoane/malawi_news_classification/data/mixup_kaggle_test.csv\", \n",
    "           final_test_preds,\n",
    "           delimiter =\",\", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
